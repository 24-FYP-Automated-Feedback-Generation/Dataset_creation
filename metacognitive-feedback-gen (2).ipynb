{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":9859425,"sourceType":"datasetVersion","datasetId":6050791},{"sourceId":5112,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":3900,"modelId":1902}],"dockerImageVersionId":30787,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"e21e395a-2736-40b0-9154-94576e51e54c","_cell_guid":"49b98bc4-6878-415f-bb06-8160a445c968","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2024-11-13T06:36:25.674091Z","iopub.execute_input":"2024-11-13T06:36:25.674402Z","iopub.status.idle":"2024-11-13T06:36:25.682158Z","shell.execute_reply.started":"2024-11-13T06:36:25.674369Z","shell.execute_reply":"2024-11-13T06:36:25.681193Z"},"jupyter":{"outputs_hidden":false}},"outputs":[{"name":"stdout","text":"/kaggle/input/feedback-dataset/modified_dataset.csv\n/kaggle/input/mistral/pytorch/7b-instruct-v0.1-hf/1/config.json\n/kaggle/input/mistral/pytorch/7b-instruct-v0.1-hf/1/pytorch_model-00002-of-00002.bin\n/kaggle/input/mistral/pytorch/7b-instruct-v0.1-hf/1/tokenizer.json\n/kaggle/input/mistral/pytorch/7b-instruct-v0.1-hf/1/tokenizer_config.json\n/kaggle/input/mistral/pytorch/7b-instruct-v0.1-hf/1/pytorch_model.bin.index.json\n/kaggle/input/mistral/pytorch/7b-instruct-v0.1-hf/1/pytorch_model-00001-of-00002.bin\n/kaggle/input/mistral/pytorch/7b-instruct-v0.1-hf/1/special_tokens_map.json\n/kaggle/input/mistral/pytorch/7b-instruct-v0.1-hf/1/.gitattributes\n/kaggle/input/mistral/pytorch/7b-instruct-v0.1-hf/1/tokenizer.model\n/kaggle/input/mistral/pytorch/7b-instruct-v0.1-hf/1/generation_config.json\n","output_type":"stream"}],"execution_count":2},{"cell_type":"markdown","source":"# Loading the dataset","metadata":{"_uuid":"dd8bb1fe-8f8b-4ea1-88cf-6b5e0d93d2e1","_cell_guid":"7da5bd42-abe1-456f-a2ba-75bab1f58c61","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"import torch\nfrom torch.utils.data import Dataset, DataLoader\nfrom tqdm import tqdm","metadata":{"_uuid":"c770b3e3-8499-4811-9ddd-ae128c9d8583","_cell_guid":"0b2258de-154d-46e2-b463-4f0e7f06cebc","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2024-11-13T06:36:25.683506Z","iopub.execute_input":"2024-11-13T06:36:25.683840Z","iopub.status.idle":"2024-11-13T06:36:27.295668Z","shell.execute_reply.started":"2024-11-13T06:36:25.683809Z","shell.execute_reply":"2024-11-13T06:36:27.294705Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"dataset = pd.read_csv('/kaggle/input/feedback-dataset/modified_dataset.csv')","metadata":{"_uuid":"cffcd871-58b5-4d51-8f3e-c6bb34815914","_cell_guid":"65ec3955-e21d-4d0f-88e5-3efc7b0e14ee","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2024-11-13T06:36:27.297595Z","iopub.execute_input":"2024-11-13T06:36:27.298012Z","iopub.status.idle":"2024-11-13T06:36:28.538510Z","shell.execute_reply.started":"2024-11-13T06:36:27.297978Z","shell.execute_reply":"2024-11-13T06:36:28.537464Z"},"jupyter":{"outputs_hidden":false}},"outputs":[{"name":"stderr","text":"/tmp/ipykernel_442/1770228850.py:1: DtypeWarning: Columns (1,2,3) have mixed types. Specify dtype option on import or set low_memory=False.\n  dataset = pd.read_csv('/kaggle/input/feedback-dataset/modified_dataset.csv')\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"dataset.head()","metadata":{"_uuid":"7764bc72-e4b9-475b-98c0-0842c8694972","_cell_guid":"d5afcf03-39e4-40be-8123-59b516ad3ba5","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2024-11-13T06:36:29.068509Z","iopub.execute_input":"2024-11-13T06:36:29.069394Z","iopub.status.idle":"2024-11-13T06:36:29.081980Z","shell.execute_reply.started":"2024-11-13T06:36:29.069339Z","shell.execute_reply":"2024-11-13T06:36:29.080977Z"},"jupyter":{"outputs_hidden":false}},"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"   sid                                       student_code  \\\n0  1.0  \"\"\" store the final answer in a variable named...   \n1  2.0  \"\"\" store the final answer in a variable named...   \n2  3.0  \"\"\" store the final answer in a variable named...   \n3  4.0  x=eval(input(\"Enter your age:\"))\\ny=str(input(...   \n4  5.0  n = str(input(\"Enter your name:\"))\\na = str(in...   \n\n                                       repaired_code  \\\n0  \"\"\" store the final answer in a variable named...   \n1  \"\"\" store the final answer in a variable named...   \n2  \"\"\" store the final answer in a variable named...   \n3  y = input(\"Enter your name:\")\\nx = eval(input(...   \n4  n = str(input(\"Enter your name:\"))\\na = str(in...   \n\n                                            feedback  \\\n0  [\\n    {\\n    'line_number': 2,\\n    'feedback...   \n1  [\\n    {\\n        'line_number': 4,\\n        '...   \n2  [\\n    {\\n        'line_number': 2,\\n        '...   \n3  [\\n    {\\n        'line_number': 1,\\n        '...   \n4  [\\n    {\\n        'line_number': 3,\\n        '...   \n\n                               metacognitive_vector  \n0  [3, 1, 3, 2, 1, 1, 2, 3, 3, 3, 2, 3, 2, 1, 2, 2]  \n1  [3, 3, 1, 3, 1, 1, 2, 2, 2, 3, 3, 3, 1, 2, 1, 3]  \n2  [3, 2, 2, 3, 3, 2, 2, 3, 3, 1, 3, 2, 1, 1, 2, 1]  \n3  [1, 1, 3, 3, 1, 3, 2, 3, 1, 1, 3, 2, 3, 1, 3, 3]  \n4  [2, 1, 2, 2, 3, 2, 3, 1, 1, 1, 2, 1, 1, 1, 2, 2]  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>sid</th>\n      <th>student_code</th>\n      <th>repaired_code</th>\n      <th>feedback</th>\n      <th>metacognitive_vector</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1.0</td>\n      <td>\"\"\" store the final answer in a variable named...</td>\n      <td>\"\"\" store the final answer in a variable named...</td>\n      <td>[\\n    {\\n    'line_number': 2,\\n    'feedback...</td>\n      <td>[3, 1, 3, 2, 1, 1, 2, 3, 3, 3, 2, 3, 2, 1, 2, 2]</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2.0</td>\n      <td>\"\"\" store the final answer in a variable named...</td>\n      <td>\"\"\" store the final answer in a variable named...</td>\n      <td>[\\n    {\\n        'line_number': 4,\\n        '...</td>\n      <td>[3, 3, 1, 3, 1, 1, 2, 2, 2, 3, 3, 3, 1, 2, 1, 3]</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3.0</td>\n      <td>\"\"\" store the final answer in a variable named...</td>\n      <td>\"\"\" store the final answer in a variable named...</td>\n      <td>[\\n    {\\n        'line_number': 2,\\n        '...</td>\n      <td>[3, 2, 2, 3, 3, 2, 2, 3, 3, 1, 3, 2, 1, 1, 2, 1]</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4.0</td>\n      <td>x=eval(input(\"Enter your age:\"))\\ny=str(input(...</td>\n      <td>y = input(\"Enter your name:\")\\nx = eval(input(...</td>\n      <td>[\\n    {\\n        'line_number': 1,\\n        '...</td>\n      <td>[1, 1, 3, 3, 1, 3, 2, 3, 1, 1, 3, 2, 3, 1, 3, 3]</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5.0</td>\n      <td>n = str(input(\"Enter your name:\"))\\na = str(in...</td>\n      <td>n = str(input(\"Enter your name:\"))\\na = str(in...</td>\n      <td>[\\n    {\\n        'line_number': 3,\\n        '...</td>\n      <td>[2, 1, 2, 2, 3, 2, 3, 1, 1, 1, 2, 1, 1, 1, 2, 2]</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":6},{"cell_type":"code","source":"data = dataset.iloc[\n:366]","metadata":{"_uuid":"dcc1690e-f219-4aa1-a390-7c28898fedd5","_cell_guid":"0c56b2e3-707a-4a6d-9722-eb863d44d3a8","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2024-11-13T06:36:38.373081Z","iopub.execute_input":"2024-11-13T06:36:38.373765Z","iopub.status.idle":"2024-11-13T06:36:38.378135Z","shell.execute_reply.started":"2024-11-13T06:36:38.373726Z","shell.execute_reply":"2024-11-13T06:36:38.377077Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"len(data)","metadata":{"_uuid":"1d83cba2-b986-4da4-99fe-9eb263d15100","_cell_guid":"d786493b-853d-4654-8ae3-4a0faa8975cf","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2024-11-13T06:36:40.634245Z","iopub.execute_input":"2024-11-13T06:36:40.635243Z","iopub.status.idle":"2024-11-13T06:36:40.640955Z","shell.execute_reply.started":"2024-11-13T06:36:40.635200Z","shell.execute_reply":"2024-11-13T06:36:40.639986Z"},"jupyter":{"outputs_hidden":false}},"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"366"},"metadata":{}}],"execution_count":9},{"cell_type":"code","source":"df = pd.DataFrame(data)  \nbatch_size = 8","metadata":{"_uuid":"46465bdb-c0f9-4320-92e5-aaef679ea902","_cell_guid":"4190384b-616a-47c3-9766-1520fbb785d6","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2024-11-13T06:36:42.526994Z","iopub.execute_input":"2024-11-13T06:36:42.528017Z","iopub.status.idle":"2024-11-13T06:36:42.532394Z","shell.execute_reply.started":"2024-11-13T06:36:42.527959Z","shell.execute_reply":"2024-11-13T06:36:42.531448Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":10},{"cell_type":"markdown","source":"# Creating the custom dataset from the Dataloader","metadata":{"_uuid":"b1bc9195-73df-4458-8491-78ec84b94b51","_cell_guid":"ccc300ce-707a-4a94-b3af-a90b4ef0ecf2","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"# Custom Dataset class for DataLoader\nclass FeedbackDataset(Dataset):\n    def __init__(self, df):\n        self.df = df\n\n    def __len__(self):\n        return len(self.df)\n\n    def __getitem__(self, idx):\n        row = self.df.iloc[idx]\n        return {\n            \"sid\": row[\"sid\"],\n            \"feedback\": row[\"feedback\"],\n            \"metacognitive_vector\": row[\"metacognitive_vector\"],\n            \"student_code\": row[\"student_code\"],\n            \"repaired_code\": row[\"repaired_code\"]\n        }","metadata":{"_uuid":"00f5b612-d7e3-43bb-af76-6c6ce50fd345","_cell_guid":"83c13247-f9e7-4449-9997-a656eea489df","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2024-11-13T06:36:44.167938Z","iopub.execute_input":"2024-11-13T06:36:44.168347Z","iopub.status.idle":"2024-11-13T06:36:44.174960Z","shell.execute_reply.started":"2024-11-13T06:36:44.168309Z","shell.execute_reply":"2024-11-13T06:36:44.173911Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"# DataLoader\ndataset = FeedbackDataset(df)\ndataloader = DataLoader(dataset, batch_size=batch_size, shuffle=False)","metadata":{"_uuid":"692669e8-d196-4e61-9ee9-d3007c9254de","_cell_guid":"4d063c61-cb6f-42c7-97c3-9fa623ebaa34","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2024-11-13T06:36:45.953898Z","iopub.execute_input":"2024-11-13T06:36:45.954313Z","iopub.status.idle":"2024-11-13T06:36:45.959500Z","shell.execute_reply.started":"2024-11-13T06:36:45.954273Z","shell.execute_reply":"2024-11-13T06:36:45.958240Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"# from transformers import AutoModelForCausalLM, AutoTokenizer\n\n# # Load gpt-neo model and tokenizer from Hugging Face\n# model_name = \"EleutherAI/gpt-neo-2.7B\"  # You can replace this with \"EleutherAI/gpt-j-6B\" for gpt-j\n# model = AutoModelForCausalLM.from_pretrained(model_name)\n# tokenizer = AutoTokenizer.from_pretrained(model_name)","metadata":{"_uuid":"b15fb397-aab1-4608-90c5-3c041b3b2b99","_cell_guid":"fd3c64a1-9d8a-44ca-ab3e-d46e2e317d94","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Loading the mistral-large-latest model","metadata":{"_uuid":"fa597594-c443-4f2b-885f-04d5a3bc6217","_cell_guid":"de98d62a-0d23-498a-9a39-e5cf46b4952a","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"pip install mistralai","metadata":{"_uuid":"c407a3d1-be1e-49a5-86a4-cde5bc574769","_cell_guid":"d09820ac-9756-408f-9ad8-9c6245b66a26","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2024-11-13T06:36:48.412052Z","iopub.execute_input":"2024-11-13T06:36:48.412935Z","iopub.status.idle":"2024-11-13T06:36:59.794025Z","shell.execute_reply.started":"2024-11-13T06:36:48.412894Z","shell.execute_reply":"2024-11-13T06:36:59.792893Z"},"jupyter":{"outputs_hidden":false}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: mistralai in /opt/conda/lib/python3.10/site-packages (1.2.2)\nRequirement already satisfied: eval-type-backport<0.3.0,>=0.2.0 in /opt/conda/lib/python3.10/site-packages (from mistralai) (0.2.0)\nRequirement already satisfied: httpx<0.28.0,>=0.27.0 in /opt/conda/lib/python3.10/site-packages (from mistralai) (0.27.0)\nRequirement already satisfied: jsonpath-python<2.0.0,>=1.0.6 in /opt/conda/lib/python3.10/site-packages (from mistralai) (1.0.6)\nRequirement already satisfied: pydantic<3.0.0,>=2.9.0 in /opt/conda/lib/python3.10/site-packages (from mistralai) (2.9.2)\nRequirement already satisfied: python-dateutil==2.8.2 in /opt/conda/lib/python3.10/site-packages (from mistralai) (2.8.2)\nRequirement already satisfied: typing-inspect<0.10.0,>=0.9.0 in /opt/conda/lib/python3.10/site-packages (from mistralai) (0.9.0)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil==2.8.2->mistralai) (1.16.0)\nRequirement already satisfied: anyio in /opt/conda/lib/python3.10/site-packages (from httpx<0.28.0,>=0.27.0->mistralai) (4.4.0)\nRequirement already satisfied: certifi in /opt/conda/lib/python3.10/site-packages (from httpx<0.28.0,>=0.27.0->mistralai) (2024.8.30)\nRequirement already satisfied: httpcore==1.* in /opt/conda/lib/python3.10/site-packages (from httpx<0.28.0,>=0.27.0->mistralai) (1.0.5)\nRequirement already satisfied: idna in /opt/conda/lib/python3.10/site-packages (from httpx<0.28.0,>=0.27.0->mistralai) (3.7)\nRequirement already satisfied: sniffio in /opt/conda/lib/python3.10/site-packages (from httpx<0.28.0,>=0.27.0->mistralai) (1.3.1)\nRequirement already satisfied: h11<0.15,>=0.13 in /opt/conda/lib/python3.10/site-packages (from httpcore==1.*->httpx<0.28.0,>=0.27.0->mistralai) (0.14.0)\nRequirement already satisfied: annotated-types>=0.6.0 in /opt/conda/lib/python3.10/site-packages (from pydantic<3.0.0,>=2.9.0->mistralai) (0.7.0)\nRequirement already satisfied: pydantic-core==2.23.4 in /opt/conda/lib/python3.10/site-packages (from pydantic<3.0.0,>=2.9.0->mistralai) (2.23.4)\nRequirement already satisfied: typing-extensions>=4.6.1 in /opt/conda/lib/python3.10/site-packages (from pydantic<3.0.0,>=2.9.0->mistralai) (4.12.2)\nRequirement already satisfied: mypy-extensions>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from typing-inspect<0.10.0,>=0.9.0->mistralai) (1.0.0)\nRequirement already satisfied: exceptiongroup>=1.0.2 in /opt/conda/lib/python3.10/site-packages (from anyio->httpx<0.28.0,>=0.27.0->mistralai) (1.2.0)\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":"# # Use a pipeline as a high-level helper\n# from transformers import pipeline\n\n# pipe = pipeline(\"text-generation\", model=\"TheBloke/Nous-Hermes-Llama2-GPTQ\")","metadata":{"_uuid":"47d559b5-d07b-4b42-8f25-b2c3b66cd0d8","_cell_guid":"bd40c763-3dd5-4736-97ae-8ffb882d2b93","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"pip install python-dotenv","metadata":{"_uuid":"fae89948-6353-4688-9de6-530c513bc79d","_cell_guid":"4c97475e-c491-4f1b-9f2b-a1421f792918","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2024-11-13T06:36:59.796415Z","iopub.execute_input":"2024-11-13T06:36:59.797358Z","iopub.status.idle":"2024-11-13T06:37:11.102662Z","shell.execute_reply.started":"2024-11-13T06:36:59.797305Z","shell.execute_reply":"2024-11-13T06:37:11.101352Z"},"jupyter":{"outputs_hidden":false}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: python-dotenv in /opt/conda/lib/python3.10/site-packages (1.0.1)\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}],"execution_count":14},{"cell_type":"code","source":"import os","metadata":{"_uuid":"ae3b8bf0-bb9c-40a6-9d9b-23ee720fb6b4","_cell_guid":"e9a80ca8-df28-4030-ab46-541770d80a7d","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2024-11-13T06:37:11.104208Z","iopub.execute_input":"2024-11-13T06:37:11.104551Z","iopub.status.idle":"2024-11-13T06:37:11.109215Z","shell.execute_reply.started":"2024-11-13T06:37:11.104515Z","shell.execute_reply":"2024-11-13T06:37:11.108238Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"os.environ[\"MISTRAL_API_KEY\"] = \"Qmo2CawcS9Ee0WkHOGUNzB4epsKmQel2\"","metadata":{"_uuid":"94216d89-f5b3-43a0-b050-b316ca17e74c","_cell_guid":"7e89ae97-deb2-4001-ba96-ad2d7e51886f","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2024-11-13T06:37:11.111497Z","iopub.execute_input":"2024-11-13T06:37:11.111837Z","iopub.status.idle":"2024-11-13T06:37:11.116943Z","shell.execute_reply.started":"2024-11-13T06:37:11.111806Z","shell.execute_reply":"2024-11-13T06:37:11.116002Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"import os\nfrom dotenv import load_dotenv\n\n\n# Load environment variables from the .env file\nload_dotenv()\n\n# Access the API key using os.getenv\napi_key = os.getenv(\"MISTRAL_API_KEY\")","metadata":{"_uuid":"f8ae79b7-e15c-4003-b91d-39935806cd65","_cell_guid":"643e0575-a1c6-4283-8e4b-039ddae38906","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2024-11-13T06:37:11.118768Z","iopub.execute_input":"2024-11-13T06:37:11.119119Z","iopub.status.idle":"2024-11-13T06:37:11.133458Z","shell.execute_reply.started":"2024-11-13T06:37:11.119078Z","shell.execute_reply":"2024-11-13T06:37:11.132594Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":17},{"cell_type":"code","source":"import os\nfrom mistralai import Mistral, UserMessage","metadata":{"_uuid":"7889c55a-29ff-4026-b598-6991e31cb5f9","_cell_guid":"a242e5a9-f5ed-4c29-98eb-99786361337a","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-11-13T06:37:11.134718Z","iopub.execute_input":"2024-11-13T06:37:11.135345Z","iopub.status.idle":"2024-11-13T06:37:11.778038Z","shell.execute_reply.started":"2024-11-13T06:37:11.135302Z","shell.execute_reply":"2024-11-13T06:37:11.777017Z"}},"outputs":[],"execution_count":18},{"cell_type":"code","source":"client = Mistral(api_key=api_key)","metadata":{"_uuid":"f1db0670-f156-41e5-846a-6603d1116938","_cell_guid":"01f4797d-f265-4ebc-8ad6-0508b4bd2e8c","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-11-13T06:37:11.779286Z","iopub.execute_input":"2024-11-13T06:37:11.779586Z","iopub.status.idle":"2024-11-13T06:37:11.804726Z","shell.execute_reply.started":"2024-11-13T06:37:11.779553Z","shell.execute_reply":"2024-11-13T06:37:11.804034Z"}},"outputs":[],"execution_count":19},{"cell_type":"code","source":"model = \"mistral-large-latest\"","metadata":{"_uuid":"b1cd76b9-70d9-483c-b0dc-e1bbf94dad30","_cell_guid":"6e6ea49c-6603-4392-8665-72c41403b190","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-11-13T06:40:54.597058Z","iopub.execute_input":"2024-11-13T06:40:54.597475Z","iopub.status.idle":"2024-11-13T06:40:54.601906Z","shell.execute_reply.started":"2024-11-13T06:40:54.597429Z","shell.execute_reply":"2024-11-13T06:40:54.600732Z"}},"outputs":[],"execution_count":27},{"cell_type":"code","source":"from transformers import MistralModel, AutoTokenizer","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-13T06:38:46.093301Z","iopub.execute_input":"2024-11-13T06:38:46.093726Z","iopub.status.idle":"2024-11-13T06:38:47.427051Z","shell.execute_reply.started":"2024-11-13T06:38:46.093681Z","shell.execute_reply":"2024-11-13T06:38:47.426289Z"}},"outputs":[],"execution_count":23},{"cell_type":"code","source":"# model = MistralModel.from_pretrained(model_type)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-13T06:40:38.247745Z","iopub.execute_input":"2024-11-13T06:40:38.248530Z","iopub.status.idle":"2024-11-13T06:40:38.252626Z","shell.execute_reply.started":"2024-11-13T06:40:38.248488Z","shell.execute_reply":"2024-11-13T06:40:38.251692Z"}},"outputs":[],"execution_count":25},{"cell_type":"code","source":"# from mistralai.client import MistralClient\n# client = Mistral(model)\n# model = Mistral(model=\"mistral-large-latest\").to(device)\n#client = Mistral(device=\"cuda\")","metadata":{"_uuid":"f8cd5fb3-a9d7-4236-ae61-1c2c4adbb8b2","_cell_guid":"c68475a2-5a80-4745-8ae2-d98dfedb5dee","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-11-13T06:40:46.223031Z","iopub.execute_input":"2024-11-13T06:40:46.223440Z","iopub.status.idle":"2024-11-13T06:40:46.227783Z","shell.execute_reply.started":"2024-11-13T06:40:46.223402Z","shell.execute_reply":"2024-11-13T06:40:46.226769Z"}},"outputs":[],"execution_count":26},{"cell_type":"code","source":"import torch\n\n# Check if CUDA is available\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel.model.to(device)  # Load model onto GPU","metadata":{"_uuid":"24fa4435-3d1e-4326-995e-388713e1c5a7","_cell_guid":"de6aeab7-e137-481b-a657-43712ad3b266","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-11-13T06:41:21.051089Z","iopub.execute_input":"2024-11-13T06:41:21.051911Z","iopub.status.idle":"2024-11-13T06:41:21.084424Z","shell.execute_reply.started":"2024-11-13T06:41:21.051869Z","shell.execute_reply":"2024-11-13T06:41:21.083022Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","Cell \u001b[0;32mIn[29], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Check if CUDA is available\u001b[39;00m\n\u001b[1;32m      4\u001b[0m device \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 5\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241m.\u001b[39mto(device)  \u001b[38;5;66;03m# Load model onto GPU\u001b[39;00m\n","\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute 'model'"],"ename":"AttributeError","evalue":"'str' object has no attribute 'model'","output_type":"error"}],"execution_count":29},{"cell_type":"code","source":"model","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-13T06:41:42.113060Z","iopub.execute_input":"2024-11-13T06:41:42.113989Z","iopub.status.idle":"2024-11-13T06:41:42.119900Z","shell.execute_reply.started":"2024-11-13T06:41:42.113945Z","shell.execute_reply":"2024-11-13T06:41:42.118921Z"}},"outputs":[{"execution_count":30,"output_type":"execute_result","data":{"text/plain":"'mistral-large-latest'"},"metadata":{}}],"execution_count":30},{"cell_type":"code","source":"# tokenizer.pad_token = tokenizer.eos_token","metadata":{"_uuid":"95e0d001-6d7d-491a-94b1-c3cb64a68857","_cell_guid":"7b187e29-f2d1-453c-b7ec-6c45e3c038f2","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# # Set pad_token_id to eos_token_id to avoid generation warnings\n# model.config.pad_token_id = model.config.eos_token_id","metadata":{"_uuid":"c63b3f0f-4db8-4e1f-a5aa-c7d12da065e8","_cell_guid":"903a7770-05f4-4858-846a-c45d5f8b0dbd","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Generating the metacognitive feedback in three steps","metadata":{"_uuid":"05c5fa2f-b52e-4e35-b51c-d470977caa6a","_cell_guid":"4df08473-81a6-490a-86dc-3ae61be7d90b","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"markdown","source":"**Generating the high level metacognitive explanation feedback of the student.**","metadata":{"_uuid":"29e30bbf-3f7b-424b-ba43-7d8d67b91917","_cell_guid":"31b7eb46-1674-44df-a33a-624d4e89595c","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"def generate_high_level_feedback(vector):\n    high_level_prompt = f\"\"\"\n    You are an AI tutor providing metacognitive feedback. Here is the student’s metacognitive vector:\n\n    Metacognitive Vector (self-regulation): {vector}\n\n    Using this vector, identify the student's:\n    - Strengths in self-regulation\n    - Areas needing improvement\n    - Suggestions for developing better self-regulation\n\n    generate a metacognitive based explanation for this student based on this 1x16vector value levels and self regulation which maps into\n    1. Problem Understanding\n    2. Requirement Identification\n    3. Summarization\n    4. Example Testing\n    5. Goal Breakdown\n    6. Pattern Recognition\n    7. Algorithm Planning\n    8. Step-by-Step Execution\n    9. Continuous Monitoring\n    10. Error Avoidance\n    11. Intermediate Result Verification\n    12. Implementation Monitoring\n    13. Data Constraints\n    14. Solution Accuracy\n    15. Requirement Fulfillment\n    16. Solution Reflection   these requirements \n\n    generate the student metacognitive level explanation using above data, precise and accurate:\n    generate a paragraph wise more clear understading feedback\n\n\n    \"\"\"\n    #inputs = tokenizer(high_level_prompt, return_tensors=\"pt\")[\"input_ids\"]\n    \n    # outputs = model.generate(\n    #     inputs,\n    #     num_return_sequences=1\n        \n        \n    # )\n    # generation_output = output[0][start_index:]\n    # high_level_feedback = tokenizer.decode(generation_output, skip_special_tokens=True)\n    # high_level_feedback = pipe(\n    # high_level_prompt,\n    # max_length=150,\n    # temperature=0.7,   # Controls randomness; lower values make output more deterministic\n    # num_return_sequences=1)\n\n    #print(feedback[0]['generated_text'])\n\n    messages = [\n    {\n        \"role\": \"user\",\n        \"content\":high_level_prompt,\n    },\n    ]\n    chat_response = client.chat.complete(\n    model = model,\n    messages = messages,\n    )\n\n#print(chat_response.choices[0].message.content)\n\n    return chat_response.choices[0].message.content","metadata":{"_uuid":"51d83d25-517f-4b53-b829-16e3ecfd081b","_cell_guid":"3e7c57b4-f724-42f8-a2ef-30c6e827cedf","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-11-13T06:51:17.200156Z","iopub.execute_input":"2024-11-13T06:51:17.201223Z","iopub.status.idle":"2024-11-13T06:51:17.210832Z","shell.execute_reply.started":"2024-11-13T06:51:17.201148Z","shell.execute_reply":"2024-11-13T06:51:17.209829Z"}},"outputs":[],"execution_count":31},{"cell_type":"markdown","source":"**Generating the problem answer feedback considering the student metacognition explained high level feedback.**","metadata":{"_uuid":"be378489-d223-4516-a3d8-bc29faed79c1","_cell_guid":"eeacd23e-97e0-418a-a2c8-56fd348b3067","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"def generate_specific_feedback(general_feedback, vector, student_code, correct_code, high_level_feedback):\n    specific_feedback_prompt = f\"\"\"\n    Based on the details below, generate feedback that helps the student improve their coding:\n\n    General Feedback: {general_feedback}\n    Metacognitive Vector (self-regulation): {vector}\n    High-Level Feedback: {high_level_feedback}\n\n    Student Code: {student_code}\n    Correct Code: {correct_code}\n\n    Provide feedback to:\n    1. Identify code errors.\n    2. Suggest improvements based on metacognitive strengths and weaknesses.\n    3. Encourage reflective coding practices.\n\n    consider above points and the student metacognitve vector and specially the high level feedback and generate more precise and concise metacognitve based explanation for the student answer by analysing the gap between student answer and the correct answer and getting the places that student need advancements considering their metacogntion explanation given by the high level feedback\n    generate a paragraph wise more clear understading student personalized feedback\n    \"\"\"\n    messages = [\n    {\n        \"role\": \"user\",\n        \"content\":specific_feedback_prompt,\n    },\n    ]\n    chat_response = client.chat.complete(\n    model = model,\n    messages = messages,\n    )\n    return chat_response.choices[0].message.content\n    \n    # inputs = tokenizer(specific_feedback_prompt, return_tensors=\"pt\")\n    # outputs = model.generate(\n    #     inputs.input_ids,\n    #     num_return_sequences=1\n\n    # )\n    # generation_output = output[0][start_index:]\n    # specific_feedback = tokenizer.decode(generation_output, skip_special_tokens=True)\n    # return specific_feedback","metadata":{"_uuid":"2eb14a33-c999-4520-a037-55bb6fe24dbc","_cell_guid":"bd098f19-3e52-4afd-a65c-49c7ef22980d","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-11-13T06:51:19.558678Z","iopub.execute_input":"2024-11-13T06:51:19.559081Z","iopub.status.idle":"2024-11-13T06:51:19.566432Z","shell.execute_reply.started":"2024-11-13T06:51:19.559040Z","shell.execute_reply":"2024-11-13T06:51:19.565452Z"}},"outputs":[],"execution_count":32},{"cell_type":"markdown","source":"*Sample generation*","metadata":{"_uuid":"ec8d99e5-84b2-43fe-a1ca-bac6786066cc","_cell_guid":"c2dfcd30-daca-441a-a7cf-5ed7fd313ab1","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"# # Define inputs\n# general_feedback = \"Remember to follow the input format strictly to avoid runtime errors.\"\n# vector = [2, 3, 1, 2, 3, 2, 1, 3, 2, 2, 1, 3, 2, 3, 1, 2]\n# student_code = 'fahre = eval(input(\"enter the temperatur in fahrenheit\")) result = ( fahre - 32 ) * 5 / 9'\n# correct_code = 'fahre = eval(input(\"enter the temperature in fahrenheit\")) result = ( fahre - 32 ) * 5 / 9'","metadata":{"_uuid":"8b550953-5bef-462f-bbd6-40f6fcb978e0","_cell_guid":"8169a30a-e6fd-427a-9abf-6fd414419d37","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# # Generate high-level feedback\n# high_level_feedback = generate_high_level_feedback(vector)\n# print(\"High-Level Feedback:\\n\", high_level_feedback)","metadata":{"_uuid":"b34dfa2d-8c1d-4b17-9714-5cce3e0a8240","_cell_guid":"07a5b6af-0ccd-467d-8b3a-f8f8c65815c8","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# # Generate specific feedback based on high-level themes\n# specific_feedback = generate_specific_feedback(general_feedback, vector, student_code, correct_code, high_level_feedback)\n# print(\"\\nSpecific Feedback:\\n\", specific_feedback)","metadata":{"_uuid":"c19c4319-9478-49d8-8252-00a08f444313","_cell_guid":"097153e4-72c2-4ddd-a5a4-332bb522b99e","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**Generating the final metacognitive feedback for the student answer incorporating student metaognition.**","metadata":{"_uuid":"6d15a75f-e8fb-4e23-89f2-9a75fe4b0575","_cell_guid":"e2a9e828-073a-4d02-951c-33f6670ecb5f","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"def final_specific_feedback(high_level_feedback, specific_feedback):\n    final_feedback_prompt = f\"\"\"\n    {specific_feedback}\n    {high_level_feedback}\n\n    Based on both feedback above, generate the most precise and personalized feedback for this student:\n    so that student can solve the fix their answer according to their metacognition. \n    generate a paragraph wise more clear understading feedback without giving the student the direct fixes to the code, explain the issues of the student considering student's metacognition\n    make the feedback more personalized and give the step  by step guidance to the student\n    \"\"\"\n    \n    messages = [\n    {\n        \"role\": \"user\",\n        \"content\":final_feedback_prompt,\n    },\n    ]\n    chat_response = client.chat.complete(\n    model = model,\n    messages = messages,\n    )\n    return chat_response.choices[0].message.content\n    \n    # inputs = tokenizer(specific_feedback_prompt, return_tensors=\"pt\")\n    # outputs = model.generate(\n    #     inputs.input_ids,\n    #     num_return_sequences=1\n\n    # )\n    # generation_output = output[0][start_index:]\n    # specific_feedback = tokenizer.decode(generation_output, skip_special_tokens=True)\n    # return specific_feedback","metadata":{"_uuid":"ff033feb-fe1d-4b64-ba1c-23257fd0ede9","_cell_guid":"e2edcac2-46dc-4674-9505-93a117ecde93","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-11-13T06:51:23.102916Z","iopub.execute_input":"2024-11-13T06:51:23.103801Z","iopub.status.idle":"2024-11-13T06:51:23.110036Z","shell.execute_reply.started":"2024-11-13T06:51:23.103756Z","shell.execute_reply":"2024-11-13T06:51:23.109012Z"}},"outputs":[],"execution_count":33},{"cell_type":"code","source":"# final_feedback = final_specific_feedback(high_level_feedback, specific_feedback)\n# print(\"\\nFinal Feedback:\\n\", final_feedback)","metadata":{"_uuid":"bdf49504-9712-4b0b-8420-3385d6287d58","_cell_guid":"980da3f6-de19-4b87-ba89-08b9edace5ab","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Dataset creation process","metadata":{"_uuid":"d366b751-4a36-4962-8eb8-401758839d27","_cell_guid":"3da4ada9-ec57-4346-87ae-bed2231d2104","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"def generate_metacognitive_feedback(row):\n    print(\"generating metacognitive vector for:\" , row['sid'])\n\n    high_level_feedback = generate_high_level_feedback(row['metacognitive_vector'])\n    specific_feedback = generate_specific_feedback(row['feedback'], row['metacognitive_vector'],row['student_code'], row['repaired_code'],high_level_feedback)\n\n    final_feedback = final_specific_feedback(high_level_feedback, specific_feedback)\n\n    return final_feedback","metadata":{"_uuid":"540a7599-142b-402c-a38a-c70e6a70e8e0","_cell_guid":"d6d118ee-533d-418a-b8a6-d44dcb34a648","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-11-13T06:51:25.246781Z","iopub.execute_input":"2024-11-13T06:51:25.247696Z","iopub.status.idle":"2024-11-13T06:51:25.252917Z","shell.execute_reply.started":"2024-11-13T06:51:25.247651Z","shell.execute_reply":"2024-11-13T06:51:25.251907Z"}},"outputs":[],"execution_count":34},{"cell_type":"markdown","source":"**Using batch processing**","metadata":{"_uuid":"9d5582c7-b997-4c91-85ca-a712e471df15","_cell_guid":"41204383-57dc-41f3-8404-8de974cf9c8b","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"# Function to generate batch feedback\ndef generate_metacognitive_feedback_batch(batch):\n    final_feedback_batch = []\n    for row in batch:\n        print(\"Generating metacognitive feedback for:\", row[\"sid\"])\n        high_level_feedback = generate_high_level_feedback(row[\"metacognitive_vector\"])\n        specific_feedback = generate_specific_feedback(\n            row[\"feedback\"], row[\"metacognitive_vector\"],\n            row[\"student_code\"], row[\"repaired_code\"],\n            high_level_feedback\n        )\n        final_feedback = final_specific_feedback(high_level_feedback, specific_feedback)\n        final_feedback_batch.append(final_feedback)\n    return final_feedback_batch","metadata":{"_uuid":"8591fcd3-709f-459a-ad02-0c0b6a3dceb5","_cell_guid":"73c46b02-869e-43a8-a80e-bb9b31a83af8","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-11-13T06:51:30.908636Z","iopub.execute_input":"2024-11-13T06:51:30.909308Z","iopub.status.idle":"2024-11-13T06:51:30.915146Z","shell.execute_reply.started":"2024-11-13T06:51:30.909266Z","shell.execute_reply":"2024-11-13T06:51:30.914237Z"}},"outputs":[],"execution_count":35},{"cell_type":"code","source":"# Process each batch and add the feedback to the DataFrame\nfinal_feedback_list = []","metadata":{"_uuid":"19dd8991-7dd7-484d-ba45-8ecf7baeb91d","_cell_guid":"24f85eba-fbf8-4849-8f18-9a93060e53dc","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-11-13T06:51:32.937497Z","iopub.execute_input":"2024-11-13T06:51:32.938135Z","iopub.status.idle":"2024-11-13T06:51:32.942125Z","shell.execute_reply.started":"2024-11-13T06:51:32.938092Z","shell.execute_reply":"2024-11-13T06:51:32.941239Z"}},"outputs":[],"execution_count":36},{"cell_type":"code","source":"len(final_feedback_list)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-13T06:51:54.261225Z","iopub.execute_input":"2024-11-13T06:51:54.261637Z","iopub.status.idle":"2024-11-13T06:51:54.268218Z","shell.execute_reply.started":"2024-11-13T06:51:54.261597Z","shell.execute_reply":"2024-11-13T06:51:54.267239Z"}},"outputs":[{"execution_count":38,"output_type":"execute_result","data":{"text/plain":"0"},"metadata":{}}],"execution_count":38},{"cell_type":"code","source":"for batch in tqdm(dataloader):\n    # Each batch is a dictionary of lists, so we create a list of dictionaries for batch processing\n    batch_list = [{key: batch[key][i] for key in batch} for i in range(len(batch[\"sid\"]))]\n    feedback_batch = generate_metacognitive_feedback_batch(batch_list)\n    final_feedback_list.extend(feedback_batch)\n    print(\"final feedback list length\" , len(final_feedback_list))","metadata":{"_uuid":"12eeb18e-837b-4303-bf3d-25b3cf67df18","_cell_guid":"2af122e0-62e6-49ab-84fe-927f8d19e091","trusted":true,"collapsed":true,"jupyter":{"outputs_hidden":true},"execution":{"iopub.status.busy":"2024-11-13T06:52:42.583535Z","iopub.execute_input":"2024-11-13T06:52:42.584291Z","iopub.status.idle":"2024-11-13T12:58:57.327599Z","shell.execute_reply.started":"2024-11-13T06:52:42.584243Z","shell.execute_reply":"2024-11-13T12:58:57.325927Z"}},"outputs":[{"name":"stderr","text":"  0%|          | 0/46 [00:00<?, ?it/s]","output_type":"stream"},{"name":"stdout","text":"Generating metacognitive feedback for: tensor(1., dtype=torch.float64)\nGenerating metacognitive feedback for: tensor(2., dtype=torch.float64)\nGenerating metacognitive feedback for: tensor(3., dtype=torch.float64)\nGenerating metacognitive feedback for: tensor(4., dtype=torch.float64)\nGenerating metacognitive feedback for: tensor(5., dtype=torch.float64)\nGenerating metacognitive feedback for: tensor(6., dtype=torch.float64)\nGenerating metacognitive feedback for: tensor(7., dtype=torch.float64)\nGenerating metacognitive feedback for: tensor(8., dtype=torch.float64)\n","output_type":"stream"},{"name":"stderr","text":"  2%|▏         | 1/46 [10:31<7:53:59, 631.98s/it]","output_type":"stream"},{"name":"stdout","text":"final feedback list length 8\nGenerating metacognitive feedback for: tensor(9., dtype=torch.float64)\nGenerating metacognitive feedback for: tensor(10., dtype=torch.float64)\nGenerating metacognitive feedback for: tensor(11., dtype=torch.float64)\nGenerating metacognitive feedback for: tensor(12., dtype=torch.float64)\nGenerating metacognitive feedback for: tensor(13., dtype=torch.float64)\nGenerating metacognitive feedback for: tensor(14., dtype=torch.float64)\nGenerating metacognitive feedback for: tensor(15., dtype=torch.float64)\nGenerating metacognitive feedback for: tensor(16., dtype=torch.float64)\n","output_type":"stream"},{"name":"stderr","text":"  4%|▍         | 2/46 [20:42<7:34:07, 619.26s/it]","output_type":"stream"},{"name":"stdout","text":"final feedback list length 16\nGenerating metacognitive feedback for: tensor(17., dtype=torch.float64)\nGenerating metacognitive feedback for: tensor(18., dtype=torch.float64)\nGenerating metacognitive feedback for: tensor(19., dtype=torch.float64)\nGenerating metacognitive feedback for: tensor(20., dtype=torch.float64)\nGenerating metacognitive feedback for: tensor(21., dtype=torch.float64)\nGenerating metacognitive feedback for: tensor(22., dtype=torch.float64)\nGenerating metacognitive feedback for: tensor(23., dtype=torch.float64)\nGenerating metacognitive feedback for: tensor(24., dtype=torch.float64)\n","output_type":"stream"},{"name":"stderr","text":"  7%|▋         | 3/46 [31:18<7:29:16, 626.90s/it]","output_type":"stream"},{"name":"stdout","text":"final feedback list length 24\nGenerating metacognitive feedback for: tensor(25., dtype=torch.float64)\nGenerating metacognitive feedback for: tensor(26., dtype=torch.float64)\nGenerating metacognitive feedback for: tensor(27., dtype=torch.float64)\nGenerating metacognitive feedback for: tensor(28., dtype=torch.float64)\nGenerating metacognitive feedback for: tensor(29., dtype=torch.float64)\nGenerating metacognitive feedback for: tensor(30., dtype=torch.float64)\nGenerating metacognitive feedback for: tensor(31., dtype=torch.float64)\nGenerating metacognitive feedback for: tensor(32., dtype=torch.float64)\n","output_type":"stream"},{"name":"stderr","text":"  9%|▊         | 4/46 [40:31<6:58:29, 597.86s/it]","output_type":"stream"},{"name":"stdout","text":"final feedback list length 32\nGenerating metacognitive feedback for: tensor(33., dtype=torch.float64)\nGenerating metacognitive feedback for: tensor(34., dtype=torch.float64)\nGenerating metacognitive feedback for: tensor(35., dtype=torch.float64)\nGenerating metacognitive feedback for: tensor(36., dtype=torch.float64)\nGenerating metacognitive feedback for: tensor(37., dtype=torch.float64)\nGenerating metacognitive feedback for: tensor(38., dtype=torch.float64)\nGenerating metacognitive feedback for: tensor(39., dtype=torch.float64)\nGenerating metacognitive feedback for: tensor(40., dtype=torch.float64)\n","output_type":"stream"},{"name":"stderr","text":" 11%|█         | 5/46 [50:02<6:41:47, 587.99s/it]","output_type":"stream"},{"name":"stdout","text":"final feedback list length 40\nGenerating metacognitive feedback for: tensor(41., dtype=torch.float64)\nGenerating metacognitive feedback for: tensor(42., dtype=torch.float64)\nGenerating metacognitive feedback for: tensor(43., dtype=torch.float64)\nGenerating metacognitive feedback for: tensor(44., dtype=torch.float64)\nGenerating metacognitive feedback for: tensor(45., dtype=torch.float64)\nGenerating metacognitive feedback for: tensor(46., dtype=torch.float64)\nGenerating metacognitive feedback for: tensor(47., dtype=torch.float64)\nGenerating metacognitive feedback for: tensor(48., dtype=torch.float64)\n","output_type":"stream"},{"name":"stderr","text":" 13%|█▎        | 6/46 [59:57<6:33:36, 590.41s/it]","output_type":"stream"},{"name":"stdout","text":"final feedback list length 48\nGenerating metacognitive feedback for: tensor(49., dtype=torch.float64)\nGenerating metacognitive feedback for: tensor(50., dtype=torch.float64)\nGenerating metacognitive feedback for: tensor(51., dtype=torch.float64)\nGenerating metacognitive feedback for: tensor(52., dtype=torch.float64)\nGenerating metacognitive feedback for: tensor(53., dtype=torch.float64)\nGenerating metacognitive feedback for: tensor(54., dtype=torch.float64)\nGenerating metacognitive feedback for: tensor(55., dtype=torch.float64)\nGenerating metacognitive feedback for: tensor(56., dtype=torch.float64)\n","output_type":"stream"},{"name":"stderr","text":" 15%|█▌        | 7/46 [1:09:42<6:22:46, 588.88s/it]","output_type":"stream"},{"name":"stdout","text":"final feedback list length 56\nGenerating metacognitive feedback for: tensor(57., dtype=torch.float64)\nGenerating metacognitive feedback for: tensor(58., dtype=torch.float64)\nGenerating metacognitive feedback for: tensor(59., dtype=torch.float64)\nGenerating metacognitive feedback for: tensor(60., dtype=torch.float64)\nGenerating metacognitive feedback for: tensor(61., dtype=torch.float64)\nGenerating metacognitive feedback for: tensor(62., dtype=torch.float64)\nGenerating metacognitive feedback for: tensor(63., dtype=torch.float64)\nGenerating metacognitive feedback for: tensor(64., dtype=torch.float64)\n","output_type":"stream"},{"name":"stderr","text":" 17%|█▋        | 8/46 [1:19:59<6:18:37, 597.82s/it]","output_type":"stream"},{"name":"stdout","text":"final feedback list length 64\nGenerating metacognitive feedback for: tensor(65., dtype=torch.float64)\nGenerating metacognitive feedback for: tensor(66., dtype=torch.float64)\nGenerating metacognitive feedback for: tensor(67., dtype=torch.float64)\nGenerating metacognitive feedback for: tensor(68., dtype=torch.float64)\nGenerating metacognitive feedback for: tensor(69., dtype=torch.float64)\nGenerating metacognitive feedback for: tensor(70., dtype=torch.float64)\nGenerating metacognitive feedback for: tensor(71., dtype=torch.float64)\nGenerating metacognitive feedback for: tensor(72., dtype=torch.float64)\n","output_type":"stream"},{"name":"stderr","text":" 20%|█▉        | 9/46 [1:30:31<6:15:10, 608.39s/it]","output_type":"stream"},{"name":"stdout","text":"final feedback list length 72\nGenerating metacognitive feedback for: tensor(73., dtype=torch.float64)\nGenerating metacognitive feedback for: tensor(74., dtype=torch.float64)\nGenerating metacognitive feedback for: tensor(75., dtype=torch.float64)\nGenerating metacognitive feedback for: tensor(76., dtype=torch.float64)\nGenerating metacognitive feedback for: tensor(77., dtype=torch.float64)\nGenerating metacognitive feedback for: tensor(78., dtype=torch.float64)\nGenerating metacognitive feedback for: tensor(79., dtype=torch.float64)\nGenerating metacognitive feedback for: tensor(80., dtype=torch.float64)\n","output_type":"stream"},{"name":"stderr","text":" 22%|██▏       | 10/46 [1:40:48<6:06:38, 611.07s/it]","output_type":"stream"},{"name":"stdout","text":"final feedback list length 80\nGenerating metacognitive feedback for: tensor(81., dtype=torch.float64)\nGenerating metacognitive feedback for: tensor(82., dtype=torch.float64)\nGenerating metacognitive feedback for: tensor(83., dtype=torch.float64)\nGenerating metacognitive feedback for: tensor(84., dtype=torch.float64)\nGenerating metacognitive feedback for: tensor(85., dtype=torch.float64)\nGenerating metacognitive feedback for: tensor(86., dtype=torch.float64)\nGenerating metacognitive feedback for: tensor(87., dtype=torch.float64)\nGenerating metacognitive feedback for: tensor(88., dtype=torch.float64)\n","output_type":"stream"},{"name":"stderr","text":" 24%|██▍       | 11/46 [1:51:05<5:57:25, 612.73s/it]","output_type":"stream"},{"name":"stdout","text":"final feedback list length 88\nGenerating metacognitive feedback for: tensor(89., dtype=torch.float64)\nGenerating metacognitive feedback for: tensor(90., dtype=torch.float64)\nGenerating metacognitive feedback for: tensor(91., dtype=torch.float64)\nGenerating metacognitive feedback for: tensor(92., dtype=torch.float64)\nGenerating metacognitive feedback for: tensor(93., dtype=torch.float64)\nGenerating metacognitive feedback for: tensor(94., dtype=torch.float64)\nGenerating metacognitive feedback for: tensor(95., dtype=torch.float64)\nGenerating metacognitive feedback for: tensor(96., dtype=torch.float64)\n","output_type":"stream"},{"name":"stderr","text":" 26%|██▌       | 12/46 [2:03:45<6:12:44, 657.78s/it]","output_type":"stream"},{"name":"stdout","text":"final feedback list length 96\nGenerating metacognitive feedback for: tensor(97., dtype=torch.float64)\nGenerating metacognitive feedback for: tensor(98., dtype=torch.float64)\nGenerating metacognitive feedback for: tensor(99., dtype=torch.float64)\nGenerating metacognitive feedback for: tensor(100., dtype=torch.float64)\nGenerating metacognitive feedback for: tensor(101., dtype=torch.float64)\nGenerating metacognitive feedback for: tensor(102., dtype=torch.float64)\nGenerating metacognitive feedback for: tensor(103., dtype=torch.float64)\nGenerating metacognitive feedback for: tensor(104., dtype=torch.float64)\n","output_type":"stream"},{"name":"stderr","text":" 28%|██▊       | 13/46 [2:14:42<6:01:37, 657.50s/it]","output_type":"stream"},{"name":"stdout","text":"final feedback list length 104\nGenerating metacognitive feedback for: tensor(105., dtype=torch.float64)\nGenerating metacognitive feedback for: tensor(106., dtype=torch.float64)\nGenerating metacognitive feedback for: tensor(107., dtype=torch.float64)\nGenerating metacognitive feedback for: tensor(108., dtype=torch.float64)\nGenerating metacognitive feedback for: tensor(109., dtype=torch.float64)\nGenerating metacognitive feedback for: tensor(110., dtype=torch.float64)\nGenerating metacognitive feedback for: tensor(111., dtype=torch.float64)\nGenerating metacognitive feedback for: tensor(112., dtype=torch.float64)\n","output_type":"stream"},{"name":"stderr","text":" 30%|███       | 14/46 [2:26:24<5:57:44, 670.78s/it]","output_type":"stream"},{"name":"stdout","text":"final feedback list length 112\nGenerating metacognitive feedback for: tensor(113., dtype=torch.float64)\nGenerating metacognitive feedback for: tensor(114., dtype=torch.float64)\nGenerating metacognitive feedback for: tensor(115., dtype=torch.float64)\nGenerating metacognitive feedback for: tensor(116., dtype=torch.float64)\nGenerating metacognitive feedback for: tensor(117., dtype=torch.float64)\nGenerating metacognitive feedback for: tensor(118., dtype=torch.float64)\nGenerating metacognitive feedback for: tensor(119., dtype=torch.float64)\nGenerating metacognitive feedback for: tensor(120., dtype=torch.float64)\n","output_type":"stream"},{"name":"stderr","text":" 33%|███▎      | 15/46 [2:38:46<5:57:40, 692.27s/it]","output_type":"stream"},{"name":"stdout","text":"final feedback list length 120\nGenerating metacognitive feedback for: tensor(121., dtype=torch.float64)\nGenerating metacognitive feedback for: tensor(122., dtype=torch.float64)\nGenerating metacognitive feedback for: tensor(123., dtype=torch.float64)\nGenerating metacognitive feedback for: tensor(124., dtype=torch.float64)\nGenerating metacognitive feedback for: tensor(125., dtype=torch.float64)\nGenerating metacognitive feedback for: tensor(126., dtype=torch.float64)\nGenerating metacognitive feedback for: tensor(127., dtype=torch.float64)\nGenerating metacognitive feedback for: tensor(128., dtype=torch.float64)\n","output_type":"stream"},{"name":"stderr","text":" 35%|███▍      | 16/46 [2:52:18<6:04:12, 728.43s/it]","output_type":"stream"},{"name":"stdout","text":"final feedback list length 128\nGenerating metacognitive feedback for: tensor(129., dtype=torch.float64)\nGenerating metacognitive feedback for: tensor(130., dtype=torch.float64)\nGenerating metacognitive feedback for: tensor(131., dtype=torch.float64)\nGenerating metacognitive feedback for: tensor(132., dtype=torch.float64)\nGenerating metacognitive feedback for: tensor(133., dtype=torch.float64)\nGenerating metacognitive feedback for: tensor(134., dtype=torch.float64)\nGenerating metacognitive feedback for: tensor(135., dtype=torch.float64)\nGenerating metacognitive feedback for: tensor(136., dtype=torch.float64)\n","output_type":"stream"},{"name":"stderr","text":" 37%|███▋      | 17/46 [3:06:36<6:10:53, 767.36s/it]","output_type":"stream"},{"name":"stdout","text":"final feedback list length 136\nGenerating metacognitive feedback for: tensor(137., dtype=torch.float64)\nGenerating metacognitive feedback for: tensor(138., dtype=torch.float64)\nGenerating metacognitive feedback for: tensor(139., dtype=torch.float64)\nGenerating metacognitive feedback for: tensor(140., dtype=torch.float64)\nGenerating metacognitive feedback for: tensor(141., dtype=torch.float64)\nGenerating metacognitive feedback for: tensor(142., dtype=torch.float64)\nGenerating metacognitive feedback for: tensor(143., dtype=torch.float64)\nGenerating metacognitive feedback for: tensor(144., dtype=torch.float64)\n","output_type":"stream"},{"name":"stderr","text":" 39%|███▉      | 18/46 [3:17:21<5:40:54, 730.51s/it]","output_type":"stream"},{"name":"stdout","text":"final feedback list length 144\nGenerating metacognitive feedback for: tensor(145., dtype=torch.float64)\nGenerating metacognitive feedback for: tensor(146., dtype=torch.float64)\nGenerating metacognitive feedback for: tensor(147., dtype=torch.float64)\nGenerating metacognitive feedback for: tensor(148., dtype=torch.float64)\nGenerating metacognitive feedback for: tensor(149., dtype=torch.float64)\nGenerating metacognitive feedback for: tensor(150., dtype=torch.float64)\nGenerating metacognitive feedback for: tensor(151., dtype=torch.float64)\nGenerating metacognitive feedback for: tensor(152., dtype=torch.float64)\n","output_type":"stream"},{"name":"stderr","text":" 41%|████▏     | 19/46 [3:28:59<5:24:21, 720.81s/it]","output_type":"stream"},{"name":"stdout","text":"final feedback list length 152\nGenerating metacognitive feedback for: tensor(153., dtype=torch.float64)\nGenerating metacognitive feedback for: tensor(154., dtype=torch.float64)\nGenerating metacognitive feedback for: tensor(155., dtype=torch.float64)\nGenerating metacognitive feedback for: tensor(156., dtype=torch.float64)\nGenerating metacognitive feedback for: tensor(157., dtype=torch.float64)\nGenerating metacognitive feedback for: tensor(158., dtype=torch.float64)\nGenerating metacognitive feedback for: tensor(159., dtype=torch.float64)\nGenerating metacognitive feedback for: tensor(160., dtype=torch.float64)\n","output_type":"stream"},{"name":"stderr","text":" 43%|████▎     | 20/46 [3:42:17<5:22:23, 743.98s/it]","output_type":"stream"},{"name":"stdout","text":"final feedback list length 160\nGenerating metacognitive feedback for: tensor(161., dtype=torch.float64)\nGenerating metacognitive feedback for: tensor(162., dtype=torch.float64)\nGenerating metacognitive feedback for: tensor(163., dtype=torch.float64)\nGenerating metacognitive feedback for: tensor(164., dtype=torch.float64)\nGenerating metacognitive feedback for: tensor(165., dtype=torch.float64)\nGenerating metacognitive feedback for: tensor(166., dtype=torch.float64)\nGenerating metacognitive feedback for: tensor(167., dtype=torch.float64)\nGenerating metacognitive feedback for: tensor(168., dtype=torch.float64)\n","output_type":"stream"},{"name":"stderr","text":" 46%|████▌     | 21/46 [3:53:18<4:59:34, 719.00s/it]","output_type":"stream"},{"name":"stdout","text":"final feedback list length 168\nGenerating metacognitive feedback for: tensor(169., dtype=torch.float64)\nGenerating metacognitive feedback for: tensor(170., dtype=torch.float64)\nGenerating metacognitive feedback for: tensor(171., dtype=torch.float64)\nGenerating metacognitive feedback for: tensor(172., dtype=torch.float64)\nGenerating metacognitive feedback for: tensor(173., dtype=torch.float64)\nGenerating metacognitive feedback for: tensor(174., dtype=torch.float64)\nGenerating metacognitive feedback for: tensor(175., dtype=torch.float64)\nGenerating metacognitive feedback for: tensor(176., dtype=torch.float64)\n","output_type":"stream"},{"name":"stderr","text":" 48%|████▊     | 22/46 [4:05:17<4:47:39, 719.16s/it]","output_type":"stream"},{"name":"stdout","text":"final feedback list length 176\nGenerating metacognitive feedback for: tensor(177., dtype=torch.float64)\nGenerating metacognitive feedback for: tensor(178., dtype=torch.float64)\nGenerating metacognitive feedback for: tensor(179., dtype=torch.float64)\nGenerating metacognitive feedback for: tensor(180., dtype=torch.float64)\nGenerating metacognitive feedback for: tensor(181., dtype=torch.float64)\nGenerating metacognitive feedback for: tensor(182., dtype=torch.float64)\nGenerating metacognitive feedback for: tensor(183., dtype=torch.float64)\nGenerating metacognitive feedback for: tensor(184., dtype=torch.float64)\n","output_type":"stream"},{"name":"stderr","text":" 50%|█████     | 23/46 [4:18:50<4:46:22, 747.08s/it]","output_type":"stream"},{"name":"stdout","text":"final feedback list length 184\nGenerating metacognitive feedback for: tensor(185., dtype=torch.float64)\nGenerating metacognitive feedback for: tensor(186., dtype=torch.float64)\nGenerating metacognitive feedback for: tensor(187., dtype=torch.float64)\nGenerating metacognitive feedback for: tensor(188., dtype=torch.float64)\nGenerating metacognitive feedback for: tensor(189., dtype=torch.float64)\nGenerating metacognitive feedback for: tensor(190., dtype=torch.float64)\nGenerating metacognitive feedback for: tensor(191., dtype=torch.float64)\nGenerating metacognitive feedback for: tensor(192., dtype=torch.float64)\n","output_type":"stream"},{"name":"stderr","text":" 52%|█████▏    | 24/46 [4:33:05<4:45:53, 779.69s/it]","output_type":"stream"},{"name":"stdout","text":"final feedback list length 192\nGenerating metacognitive feedback for: tensor(193., dtype=torch.float64)\nGenerating metacognitive feedback for: tensor(194., dtype=torch.float64)\nGenerating metacognitive feedback for: tensor(195., dtype=torch.float64)\nGenerating metacognitive feedback for: tensor(196., dtype=torch.float64)\nGenerating metacognitive feedback for: tensor(197., dtype=torch.float64)\nGenerating metacognitive feedback for: tensor(198., dtype=torch.float64)\nGenerating metacognitive feedback for: tensor(199., dtype=torch.float64)\nGenerating metacognitive feedback for: tensor(200., dtype=torch.float64)\n","output_type":"stream"},{"name":"stderr","text":" 54%|█████▍    | 25/46 [4:46:35<4:36:05, 788.82s/it]","output_type":"stream"},{"name":"stdout","text":"final feedback list length 200\nGenerating metacognitive feedback for: tensor(201., dtype=torch.float64)\nGenerating metacognitive feedback for: tensor(202., dtype=torch.float64)\nGenerating metacognitive feedback for: tensor(203., dtype=torch.float64)\nGenerating metacognitive feedback for: tensor(204., dtype=torch.float64)\nGenerating metacognitive feedback for: tensor(205., dtype=torch.float64)\nGenerating metacognitive feedback for: tensor(206., dtype=torch.float64)\nGenerating metacognitive feedback for: tensor(207., dtype=torch.float64)\nGenerating metacognitive feedback for: tensor(208., dtype=torch.float64)\n","output_type":"stream"},{"name":"stderr","text":" 57%|█████▋    | 26/46 [4:58:46<4:17:07, 771.36s/it]","output_type":"stream"},{"name":"stdout","text":"final feedback list length 208\nGenerating metacognitive feedback for: tensor(209., dtype=torch.float64)\nGenerating metacognitive feedback for: tensor(210., dtype=torch.float64)\nGenerating metacognitive feedback for: tensor(211., dtype=torch.float64)\nGenerating metacognitive feedback for: tensor(212., dtype=torch.float64)\nGenerating metacognitive feedback for: tensor(213., dtype=torch.float64)\nGenerating metacognitive feedback for: tensor(214., dtype=torch.float64)\nGenerating metacognitive feedback for: tensor(215., dtype=torch.float64)\nGenerating metacognitive feedback for: tensor(216., dtype=torch.float64)\n","output_type":"stream"},{"name":"stderr","text":" 59%|█████▊    | 27/46 [5:11:00<4:00:42, 760.14s/it]","output_type":"stream"},{"name":"stdout","text":"final feedback list length 216\nGenerating metacognitive feedback for: tensor(217., dtype=torch.float64)\nGenerating metacognitive feedback for: tensor(218., dtype=torch.float64)\nGenerating metacognitive feedback for: tensor(219., dtype=torch.float64)\nGenerating metacognitive feedback for: tensor(220., dtype=torch.float64)\nGenerating metacognitive feedback for: tensor(221., dtype=torch.float64)\nGenerating metacognitive feedback for: tensor(222., dtype=torch.float64)\nGenerating metacognitive feedback for: tensor(223., dtype=torch.float64)\nGenerating metacognitive feedback for: tensor(224., dtype=torch.float64)\n","output_type":"stream"},{"name":"stderr","text":" 61%|██████    | 28/46 [5:23:00<3:44:24, 748.04s/it]","output_type":"stream"},{"name":"stdout","text":"final feedback list length 224\nGenerating metacognitive feedback for: tensor(225., dtype=torch.float64)\nGenerating metacognitive feedback for: tensor(226., dtype=torch.float64)\nGenerating metacognitive feedback for: tensor(227., dtype=torch.float64)\nGenerating metacognitive feedback for: tensor(228., dtype=torch.float64)\nGenerating metacognitive feedback for: tensor(229., dtype=torch.float64)\nGenerating metacognitive feedback for: tensor(230., dtype=torch.float64)\nGenerating metacognitive feedback for: tensor(231., dtype=torch.float64)\nGenerating metacognitive feedback for: tensor(232., dtype=torch.float64)\n","output_type":"stream"},{"name":"stderr","text":" 63%|██████▎   | 29/46 [5:39:49<3:54:09, 826.44s/it]","output_type":"stream"},{"name":"stdout","text":"final feedback list length 232\nGenerating metacognitive feedback for: tensor(233., dtype=torch.float64)\nGenerating metacognitive feedback for: tensor(234., dtype=torch.float64)\nGenerating metacognitive feedback for: tensor(235., dtype=torch.float64)\nGenerating metacognitive feedback for: tensor(236., dtype=torch.float64)\nGenerating metacognitive feedback for: tensor(237., dtype=torch.float64)\nGenerating metacognitive feedback for: tensor(238., dtype=torch.float64)\nGenerating metacognitive feedback for: tensor(239., dtype=torch.float64)\nGenerating metacognitive feedback for: tensor(240., dtype=torch.float64)\n","output_type":"stream"},{"name":"stderr","text":" 65%|██████▌   | 30/46 [5:51:02<3:28:04, 780.27s/it]","output_type":"stream"},{"name":"stdout","text":"final feedback list length 240\nGenerating metacognitive feedback for: tensor(241., dtype=torch.float64)\nGenerating metacognitive feedback for: tensor(242., dtype=torch.float64)\nGenerating metacognitive feedback for: tensor(243., dtype=torch.float64)\nGenerating metacognitive feedback for: tensor(244., dtype=torch.float64)\nGenerating metacognitive feedback for: tensor(245., dtype=torch.float64)\nGenerating metacognitive feedback for: tensor(246., dtype=torch.float64)\nGenerating metacognitive feedback for: tensor(247., dtype=torch.float64)\nGenerating metacognitive feedback for: tensor(248., dtype=torch.float64)\n","output_type":"stream"},{"name":"stderr","text":" 67%|██████▋   | 31/46 [6:02:35<3:08:30, 754.03s/it]","output_type":"stream"},{"name":"stdout","text":"final feedback list length 248\nGenerating metacognitive feedback for: tensor(249., dtype=torch.float64)\nGenerating metacognitive feedback for: tensor(250., dtype=torch.float64)\nGenerating metacognitive feedback for: tensor(251., dtype=torch.float64)\n","output_type":"stream"},{"name":"stderr","text":" 67%|██████▋   | 31/46 [6:06:14<2:57:12, 708.86s/it]\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mSDKError\u001b[0m                                  Traceback (most recent call last)","Cell \u001b[0;32mIn[39], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m tqdm(dataloader):\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;66;03m# Each batch is a dictionary of lists, so we create a list of dictionaries for batch processing\u001b[39;00m\n\u001b[1;32m      3\u001b[0m     batch_list \u001b[38;5;241m=\u001b[39m [{key: batch[key][i] \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m batch} \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(batch[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msid\u001b[39m\u001b[38;5;124m\"\u001b[39m]))]\n\u001b[0;32m----> 4\u001b[0m     feedback_batch \u001b[38;5;241m=\u001b[39m \u001b[43mgenerate_metacognitive_feedback_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_list\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m     final_feedback_list\u001b[38;5;241m.\u001b[39mextend(feedback_batch)\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfinal feedback list length\u001b[39m\u001b[38;5;124m\"\u001b[39m , \u001b[38;5;28mlen\u001b[39m(final_feedback_list))\n","Cell \u001b[0;32mIn[35], line 6\u001b[0m, in \u001b[0;36mgenerate_metacognitive_feedback_batch\u001b[0;34m(batch)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m row \u001b[38;5;129;01min\u001b[39;00m batch:\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGenerating metacognitive feedback for:\u001b[39m\u001b[38;5;124m\"\u001b[39m, row[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msid\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m----> 6\u001b[0m     high_level_feedback \u001b[38;5;241m=\u001b[39m \u001b[43mgenerate_high_level_feedback\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmetacognitive_vector\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m     specific_feedback \u001b[38;5;241m=\u001b[39m generate_specific_feedback(\n\u001b[1;32m      8\u001b[0m         row[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfeedback\u001b[39m\u001b[38;5;124m\"\u001b[39m], row[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetacognitive_vector\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m      9\u001b[0m         row[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstudent_code\u001b[39m\u001b[38;5;124m\"\u001b[39m], row[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrepaired_code\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m     10\u001b[0m         high_level_feedback\n\u001b[1;32m     11\u001b[0m     )\n\u001b[1;32m     12\u001b[0m     final_feedback \u001b[38;5;241m=\u001b[39m final_specific_feedback(high_level_feedback, specific_feedback)\n","Cell \u001b[0;32mIn[31], line 59\u001b[0m, in \u001b[0;36mgenerate_high_level_feedback\u001b[0;34m(vector)\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[38;5;66;03m#inputs = tokenizer(high_level_prompt, return_tensors=\"pt\")[\"input_ids\"]\u001b[39;00m\n\u001b[1;32m     36\u001b[0m     \n\u001b[1;32m     37\u001b[0m     \u001b[38;5;66;03m# outputs = model.generate(\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     50\u001b[0m \n\u001b[1;32m     51\u001b[0m     \u001b[38;5;66;03m#print(feedback[0]['generated_text'])\u001b[39;00m\n\u001b[1;32m     53\u001b[0m     messages \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     54\u001b[0m     {\n\u001b[1;32m     55\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrole\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     56\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m:high_level_prompt,\n\u001b[1;32m     57\u001b[0m     },\n\u001b[1;32m     58\u001b[0m     ]\n\u001b[0;32m---> 59\u001b[0m     chat_response \u001b[38;5;241m=\u001b[39m \u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchat\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcomplete\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     60\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     61\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     62\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;66;03m#print(chat_response.choices[0].message.content)\u001b[39;00m\n\u001b[1;32m     66\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m chat_response\u001b[38;5;241m.\u001b[39mchoices[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mmessage\u001b[38;5;241m.\u001b[39mcontent\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/mistralai/chat.py:145\u001b[0m, in \u001b[0;36mChat.complete\u001b[0;34m(self, model, messages, temperature, top_p, max_tokens, stream, stop, random_seed, response_format, tools, tool_choice, presence_penalty, frequency_penalty, n, safe_prompt, retries, server_url, timeout_ms)\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m utils\u001b[38;5;241m.\u001b[39mmatch_response(http_res, [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m4XX\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m5XX\u001b[39m\u001b[38;5;124m\"\u001b[39m], \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m*\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    144\u001b[0m     http_res_text \u001b[38;5;241m=\u001b[39m utils\u001b[38;5;241m.\u001b[39mstream_to_text(http_res)\n\u001b[0;32m--> 145\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m models\u001b[38;5;241m.\u001b[39mSDKError(\n\u001b[1;32m    146\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAPI error occurred\u001b[39m\u001b[38;5;124m\"\u001b[39m, http_res\u001b[38;5;241m.\u001b[39mstatus_code, http_res_text, http_res\n\u001b[1;32m    147\u001b[0m     )\n\u001b[1;32m    149\u001b[0m content_type \u001b[38;5;241m=\u001b[39m http_res\u001b[38;5;241m.\u001b[39mheaders\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mContent-Type\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    150\u001b[0m http_res_text \u001b[38;5;241m=\u001b[39m utils\u001b[38;5;241m.\u001b[39mstream_to_text(http_res)\n","\u001b[0;31mSDKError\u001b[0m: API error occurred: Status 502\n<html>\r\n<head><title>502 Bad Gateway</title></head>\r\n<body>\r\n<center><h1>502 Bad Gateway</h1></center>\r\n<hr><center>cloudflare</center>\r\n</body>\r\n</html>\r\n"],"ename":"SDKError","evalue":"API error occurred: Status 502\n<html>\r\n<head><title>502 Bad Gateway</title></head>\r\n<body>\r\n<center><h1>502 Bad Gateway</h1></center>\r\n<hr><center>cloudflare</center>\r\n</body>\r\n</html>\r\n","output_type":"error"}],"execution_count":39},{"cell_type":"code","source":"final_feedback_list[50]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-13T13:35:23.158988Z","iopub.execute_input":"2024-11-13T13:35:23.159777Z","iopub.status.idle":"2024-11-13T13:35:23.165704Z","shell.execute_reply.started":"2024-11-13T13:35:23.159734Z","shell.execute_reply":"2024-11-13T13:35:23.164875Z"}},"outputs":[{"execution_count":42,"output_type":"execute_result","data":{"text/plain":"\"### Personalized Feedback on Code Errors and Improvements\\n\\n#### Identified Code Errors\\n\\nYour current implementation of the Fibonacci sequence uses a recursive approach, which, while straightforward, can be highly inefficient for larger inputs due to repeated computations. Specifically, your code:\\n\\n```python\\ndef fibo(n):\\n    if n == 1 or n == 2:\\n        return 1\\n```\\n\\nlacks the iterative computation that would make it more efficient for larger values of `n`.\\n\\n#### Suggested Improvements Based on Metacognitive Strengths and Weaknesses\\n\\nGiven your strengths in **Problem Understanding**, **Summarization**, **Example Testing**, **Data Constraints**, and **Solution Reflection**, you have a good foundation for tackling the problem. However, the areas needing improvement can be addressed to enhance your code.\\n\\n1. **Requirement Identification and Breakdown**: You need to break down the problem into smaller steps. Instead of using recursion, consider breaking down the Fibonacci calculation into an iterative process. This involves starting with the first two numbers and repeatedly calculating the next number by adding the last two.\\n\\n2. **Pattern Recognition**: Recognize the pattern in the Fibonacci sequence, where each number is the sum of the two preceding ones. This pattern can be efficiently implemented using a loop.\\n\\n3. **Algorithm Planning and Step-by-Step Execution**: Plan your algorithm before writing the code. This would involve initializing two variables to 1 (representing the first two Fibonacci numbers), then using a loop to update these variables iteratively.\\n\\n### Encouraging Reflective Coding Practices\\n\\nTo enhance your coding practices and align them with your metacognitive strengths and weaknesses, consider the following:\\n\\n1. **Requirement Fulfillment and Solution Accuracy**: Ensure that your solution meets all requirements by double-checking your code. For example, in your initial code, the recursive approach does not efficiently fulfill the requirement for larger inputs. The iterative approach ensures that the solution is both accurate and efficient.\\n\\n2. **Continuous Monitoring and Error Avoidance**: Implement regular checkpoints during your coding process. For instance, after writing the initial base cases, test them individually before proceeding with the loop. This helps in identifying and correcting errors early.\\n\\n3. **Intermediate Result Verification and Implementation Monitoring**: Verify intermediate results frequently. For the Fibonacci sequence, you can print the values of `a` and `b` at each step of the loop to ensure they are being updated correctly.\\n\\n4. **Pattern Recognition**: Engage in exercises that enhance your pattern recognition skills. This will help you identify efficient algorithms and data structures for solving problems. For the Fibonacci sequence, recognizing the iterative pattern is crucial for an efficient solution.\\n\\nBy focusing on these areas, you can significantly improve your self-regulation skills and coding practices, leading to more effective problem-solving and greater success in your academic and professional endeavors. Keep up the good work in areas where you are strong, and continuously strive to improve in areas where you need development.\\n\\n### Metacognitive Feedback\\n\\n#### Strengths in Self-Regulation\\n\\nYou demonstrate notable strengths in several areas of self-regulation. Specifically, you show strong capabilities (level 3) in **Problem Understanding**, **Summarization**, **Example Testing**, **Data Constraints**, and **Solution Reflection**. These strengths indicate that you are adept at comprehending the problem at hand, effectively summarizing information, testing ideas through examples, understanding data constraints, and reflecting on the solution's quality. These competencies are crucial for tackling complex tasks and ensuring that the solutions are well-thought-out and accurate.\\n\\n#### Areas Needing Improvement\\n\\nHowever, there are several areas where your self-regulation skills need improvement. You show weaknesses (level 1) in **Requirement Identification**, **Goal Breakdown**, **Pattern Recognition**, **Requirement Fulfillment**, and **Solution Accuracy**. Additionally, you have moderate skills (level 2) in **Algorithm Planning**, **Step-by-Step Execution**, **Continuous Monitoring**, **Error Avoidance**, **Intermediate Result Verification**, and **Implementation Monitoring**. These areas suggest that you may struggle with identifying and breaking down requirements, recognizing patterns, ensuring that the solution meets all requirements, and maintaining accuracy. The moderate skills indicate that you can execute steps and monitor progress but may not be doing so consistently or effectively.\\n\\n#### Suggestions for Developing Better Self-Regulation\\n\\nTo improve self-regulation, you should focus on the following strategies:\\n\\n1. **Requirement Identification and Breakdown**: Practice breaking down complex problems into smaller, manageable parts. Use tools like mind maps or outlines to visualize and organize requirements.\\n\\n2. **Pattern Recognition**: Engage in exercises that enhance pattern recognition skills. This could include solving puzzles, analyzing data sets for trends, or practicing with pattern-based problems.\\n\\n3. **Algorithm Planning and Step-by-Step Execution**: Develop a habit of planning algorithms in a structured manner before execution. Use pseudocode or flowcharts to map out the steps clearly.\\n\\n4. **Continuous Monitoring and Error Avoidance**: Implement regular checkpoints during problem-solving to monitor progress and identify potential errors early. Keep a log of steps taken and results obtained to track progress.\\n\\n5. **Intermediate Result Verification and Implementation Monitoring**: Verify intermediate results frequently to ensure they are correct before proceeding to the next step. Use checklists or validation methods to monitor the implementation process.\\n\\n6. **Requirement Fulfillment and Solution Accuracy**: Double-check that all requirements are met and that the solution is accurate. Use peer reviews or automated testing tools to ensure thoroughness and accuracy.\\n\\nBy focusing on these areas, you can enhance your self-regulation skills, leading to more effective problem-solving and greater overall success in academic and professional endeavors.\""},"metadata":{}}],"execution_count":42},{"cell_type":"code","source":"len(final_feedback_list)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-13T15:44:24.423812Z","iopub.execute_input":"2024-11-13T15:44:24.424208Z","iopub.status.idle":"2024-11-13T15:44:24.430508Z","shell.execute_reply.started":"2024-11-13T15:44:24.424152Z","shell.execute_reply":"2024-11-13T15:44:24.429626Z"}},"outputs":[{"execution_count":51,"output_type":"execute_result","data":{"text/plain":"248"},"metadata":{}}],"execution_count":51},{"cell_type":"code","source":"final=[]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-13T14:24:14.074098Z","iopub.execute_input":"2024-11-13T14:24:14.074506Z","iopub.status.idle":"2024-11-13T14:24:14.078823Z","shell.execute_reply.started":"2024-11-13T14:24:14.074468Z","shell.execute_reply":"2024-11-13T14:24:14.077895Z"}},"outputs":[],"execution_count":46},{"cell_type":"code","source":"for batch in tqdm(dataloader):\n    # Each batch is a dictionary of lists, so we create a list of dictionaries for batch processing\n    batch_list = [{key: batch[key][i] for key in batch} for i in range(len(batch[\"sid\"]))]\n    feedback_batch = generate_metacognitive_feedback_batch(batch_list)\n    final.extend(feedback_batch)\n    print(\"final feedback list length\" , len(final))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-13T14:24:16.248398Z","iopub.execute_input":"2024-11-13T14:24:16.249153Z","iopub.status.idle":"2024-11-13T15:43:26.847251Z","shell.execute_reply.started":"2024-11-13T14:24:16.249113Z","shell.execute_reply":"2024-11-13T15:43:26.845516Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[{"name":"stderr","text":"  0%|          | 0/46 [00:00<?, ?it/s]","output_type":"stream"},{"name":"stdout","text":"Generating metacognitive feedback for: tensor(1., dtype=torch.float64)\nGenerating metacognitive feedback for: tensor(2., dtype=torch.float64)\nGenerating metacognitive feedback for: tensor(3., dtype=torch.float64)\nGenerating metacognitive feedback for: tensor(4., dtype=torch.float64)\nGenerating metacognitive feedback for: tensor(5., dtype=torch.float64)\nGenerating metacognitive feedback for: tensor(6., dtype=torch.float64)\nGenerating metacognitive feedback for: tensor(7., dtype=torch.float64)\nGenerating metacognitive feedback for: tensor(8., dtype=torch.float64)\n","output_type":"stream"},{"name":"stderr","text":"  2%|▏         | 1/46 [11:18<8:28:33, 678.07s/it]","output_type":"stream"},{"name":"stdout","text":"final feedback list length 8\nGenerating metacognitive feedback for: tensor(9., dtype=torch.float64)\nGenerating metacognitive feedback for: tensor(10., dtype=torch.float64)\nGenerating metacognitive feedback for: tensor(11., dtype=torch.float64)\nGenerating metacognitive feedback for: tensor(12., dtype=torch.float64)\nGenerating metacognitive feedback for: tensor(13., dtype=torch.float64)\nGenerating metacognitive feedback for: tensor(14., dtype=torch.float64)\nGenerating metacognitive feedback for: tensor(15., dtype=torch.float64)\nGenerating metacognitive feedback for: tensor(16., dtype=torch.float64)\n","output_type":"stream"},{"name":"stderr","text":"  4%|▍         | 2/46 [22:45<8:21:10, 683.42s/it]","output_type":"stream"},{"name":"stdout","text":"final feedback list length 16\nGenerating metacognitive feedback for: tensor(17., dtype=torch.float64)\nGenerating metacognitive feedback for: tensor(18., dtype=torch.float64)\nGenerating metacognitive feedback for: tensor(19., dtype=torch.float64)\nGenerating metacognitive feedback for: tensor(20., dtype=torch.float64)\nGenerating metacognitive feedback for: tensor(21., dtype=torch.float64)\nGenerating metacognitive feedback for: tensor(22., dtype=torch.float64)\nGenerating metacognitive feedback for: tensor(23., dtype=torch.float64)\nGenerating metacognitive feedback for: tensor(24., dtype=torch.float64)\n","output_type":"stream"},{"name":"stderr","text":"  7%|▋         | 3/46 [35:03<8:27:39, 708.36s/it]","output_type":"stream"},{"name":"stdout","text":"final feedback list length 24\nGenerating metacognitive feedback for: tensor(25., dtype=torch.float64)\nGenerating metacognitive feedback for: tensor(26., dtype=torch.float64)\nGenerating metacognitive feedback for: tensor(27., dtype=torch.float64)\nGenerating metacognitive feedback for: tensor(28., dtype=torch.float64)\nGenerating metacognitive feedback for: tensor(29., dtype=torch.float64)\nGenerating metacognitive feedback for: tensor(30., dtype=torch.float64)\nGenerating metacognitive feedback for: tensor(31., dtype=torch.float64)\nGenerating metacognitive feedback for: tensor(32., dtype=torch.float64)\n","output_type":"stream"},{"name":"stderr","text":"  9%|▊         | 4/46 [46:56<8:17:06, 710.15s/it]","output_type":"stream"},{"name":"stdout","text":"final feedback list length 32\nGenerating metacognitive feedback for: tensor(33., dtype=torch.float64)\nGenerating metacognitive feedback for: tensor(34., dtype=torch.float64)\nGenerating metacognitive feedback for: tensor(35., dtype=torch.float64)\nGenerating metacognitive feedback for: tensor(36., dtype=torch.float64)\nGenerating metacognitive feedback for: tensor(37., dtype=torch.float64)\nGenerating metacognitive feedback for: tensor(38., dtype=torch.float64)\nGenerating metacognitive feedback for: tensor(39., dtype=torch.float64)\nGenerating metacognitive feedback for: tensor(40., dtype=torch.float64)\n","output_type":"stream"},{"name":"stderr","text":" 11%|█         | 5/46 [58:23<7:59:43, 702.03s/it]","output_type":"stream"},{"name":"stdout","text":"final feedback list length 40\nGenerating metacognitive feedback for: tensor(41., dtype=torch.float64)\nGenerating metacognitive feedback for: tensor(42., dtype=torch.float64)\nGenerating metacognitive feedback for: tensor(43., dtype=torch.float64)\nGenerating metacognitive feedback for: tensor(44., dtype=torch.float64)\nGenerating metacognitive feedback for: tensor(45., dtype=torch.float64)\nGenerating metacognitive feedback for: tensor(46., dtype=torch.float64)\nGenerating metacognitive feedback for: tensor(47., dtype=torch.float64)\nGenerating metacognitive feedback for: tensor(48., dtype=torch.float64)\n","output_type":"stream"},{"name":"stderr","text":" 13%|█▎        | 6/46 [1:08:59<7:32:57, 679.44s/it]","output_type":"stream"},{"name":"stdout","text":"final feedback list length 48\nGenerating metacognitive feedback for: tensor(49., dtype=torch.float64)\nGenerating metacognitive feedback for: tensor(50., dtype=torch.float64)\nGenerating metacognitive feedback for: tensor(51., dtype=torch.float64)\nGenerating metacognitive feedback for: tensor(52., dtype=torch.float64)\nGenerating metacognitive feedback for: tensor(53., dtype=torch.float64)\nGenerating metacognitive feedback for: tensor(54., dtype=torch.float64)\nGenerating metacognitive feedback for: tensor(55., dtype=torch.float64)\nGenerating metacognitive feedback for: tensor(56., dtype=torch.float64)\n","output_type":"stream"},{"name":"stderr","text":" 13%|█▎        | 6/46 [1:19:10<8:47:48, 791.71s/it]\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[47], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m tqdm(dataloader):\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;66;03m# Each batch is a dictionary of lists, so we create a list of dictionaries for batch processing\u001b[39;00m\n\u001b[1;32m      3\u001b[0m     batch_list \u001b[38;5;241m=\u001b[39m [{key: batch[key][i] \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m batch} \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(batch[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msid\u001b[39m\u001b[38;5;124m\"\u001b[39m]))]\n\u001b[0;32m----> 4\u001b[0m     feedback_batch \u001b[38;5;241m=\u001b[39m \u001b[43mgenerate_metacognitive_feedback_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_list\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m     final\u001b[38;5;241m.\u001b[39mextend(feedback_batch)\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfinal feedback list length\u001b[39m\u001b[38;5;124m\"\u001b[39m , \u001b[38;5;28mlen\u001b[39m(final))\n","Cell \u001b[0;32mIn[35], line 7\u001b[0m, in \u001b[0;36mgenerate_metacognitive_feedback_batch\u001b[0;34m(batch)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGenerating metacognitive feedback for:\u001b[39m\u001b[38;5;124m\"\u001b[39m, row[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msid\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m      6\u001b[0m high_level_feedback \u001b[38;5;241m=\u001b[39m generate_high_level_feedback(row[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetacognitive_vector\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m----> 7\u001b[0m specific_feedback \u001b[38;5;241m=\u001b[39m \u001b[43mgenerate_specific_feedback\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfeedback\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmetacognitive_vector\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstudent_code\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrepaired_code\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhigh_level_feedback\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m final_feedback \u001b[38;5;241m=\u001b[39m final_specific_feedback(high_level_feedback, specific_feedback)\n\u001b[1;32m     13\u001b[0m final_feedback_batch\u001b[38;5;241m.\u001b[39mappend(final_feedback)\n","Cell \u001b[0;32mIn[32], line 26\u001b[0m, in \u001b[0;36mgenerate_specific_feedback\u001b[0;34m(general_feedback, vector, student_code, correct_code, high_level_feedback)\u001b[0m\n\u001b[1;32m      2\u001b[0m specific_feedback_prompt \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;124mBased on the details below, generate feedback that helps the student improve their coding:\u001b[39m\n\u001b[1;32m      4\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;124mgenerate a paragraph wise more clear understading student personalized feedback\u001b[39m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;124m\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m     20\u001b[0m messages \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     21\u001b[0m {\n\u001b[1;32m     22\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrole\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     23\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m:specific_feedback_prompt,\n\u001b[1;32m     24\u001b[0m },\n\u001b[1;32m     25\u001b[0m ]\n\u001b[0;32m---> 26\u001b[0m chat_response \u001b[38;5;241m=\u001b[39m \u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchat\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcomplete\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[43m\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     28\u001b[0m \u001b[43m\u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     29\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m chat_response\u001b[38;5;241m.\u001b[39mchoices[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mmessage\u001b[38;5;241m.\u001b[39mcontent\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/mistralai/chat.py:122\u001b[0m, in \u001b[0;36mChat.complete\u001b[0;34m(self, model, messages, temperature, top_p, max_tokens, stream, stop, random_seed, response_format, tools, tool_choice, presence_penalty, frequency_penalty, n, safe_prompt, retries, server_url, timeout_ms)\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(retries, utils\u001b[38;5;241m.\u001b[39mRetryConfig):\n\u001b[1;32m    120\u001b[0m     retry_config \u001b[38;5;241m=\u001b[39m (retries, [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m429\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m500\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m502\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m503\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m504\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m--> 122\u001b[0m http_res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdo_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    123\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhook_ctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mHookContext\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    124\u001b[0m \u001b[43m        \u001b[49m\u001b[43moperation_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mchat_completion_v1_chat_completions_post\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    125\u001b[0m \u001b[43m        \u001b[49m\u001b[43moauth2_scopes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    126\u001b[0m \u001b[43m        \u001b[49m\u001b[43msecurity_source\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mget_security_from_env\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    127\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msdk_configuration\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msecurity\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodels\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mSecurity\u001b[49m\n\u001b[1;32m    128\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    129\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    130\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreq\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    131\u001b[0m \u001b[43m    \u001b[49m\u001b[43merror_status_codes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m422\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m4XX\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m5XX\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    132\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretry_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretry_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    133\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    135\u001b[0m data: Any \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    136\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m utils\u001b[38;5;241m.\u001b[39mmatch_response(http_res, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m200\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mapplication/json\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/mistralai/basesdk.py:257\u001b[0m, in \u001b[0;36mBaseSDK.do_request\u001b[0;34m(self, hook_ctx, request, error_status_codes, stream, retry_config)\u001b[0m\n\u001b[1;32m    255\u001b[0m     http_res \u001b[38;5;241m=\u001b[39m utils\u001b[38;5;241m.\u001b[39mretry(do, utils\u001b[38;5;241m.\u001b[39mRetries(retry_config[\u001b[38;5;241m0\u001b[39m], retry_config[\u001b[38;5;241m1\u001b[39m]))\n\u001b[1;32m    256\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 257\u001b[0m     http_res \u001b[38;5;241m=\u001b[39m \u001b[43mdo\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    259\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m utils\u001b[38;5;241m.\u001b[39mmatch_status_codes(error_status_codes, http_res\u001b[38;5;241m.\u001b[39mstatus_code):\n\u001b[1;32m    260\u001b[0m     http_res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msdk_configuration\u001b[38;5;241m.\u001b[39mget_hooks()\u001b[38;5;241m.\u001b[39mafter_success(\n\u001b[1;32m    261\u001b[0m         AfterSuccessContext(hook_ctx), http_res\n\u001b[1;32m    262\u001b[0m     )\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/mistralai/basesdk.py:218\u001b[0m, in \u001b[0;36mBaseSDK.do_request.<locals>.do\u001b[0;34m()\u001b[0m\n\u001b[1;32m    208\u001b[0m     req \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msdk_configuration\u001b[38;5;241m.\u001b[39mget_hooks()\u001b[38;5;241m.\u001b[39mbefore_request(\n\u001b[1;32m    209\u001b[0m         BeforeRequestContext(hook_ctx), request\n\u001b[1;32m    210\u001b[0m     )\n\u001b[1;32m    211\u001b[0m     logger\u001b[38;5;241m.\u001b[39mdebug(\n\u001b[1;32m    212\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRequest:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mMethod: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mURL: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mHeaders: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mBody: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    213\u001b[0m         req\u001b[38;5;241m.\u001b[39mmethod,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    216\u001b[0m         get_body_content(req),\n\u001b[1;32m    217\u001b[0m     )\n\u001b[0;32m--> 218\u001b[0m     http_res \u001b[38;5;241m=\u001b[39m \u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    219\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    220\u001b[0m     _, e \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msdk_configuration\u001b[38;5;241m.\u001b[39mget_hooks()\u001b[38;5;241m.\u001b[39mafter_error(\n\u001b[1;32m    221\u001b[0m         AfterErrorContext(hook_ctx), \u001b[38;5;28;01mNone\u001b[39;00m, e\n\u001b[1;32m    222\u001b[0m     )\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/httpx/_client.py:914\u001b[0m, in \u001b[0;36mClient.send\u001b[0;34m(self, request, stream, auth, follow_redirects)\u001b[0m\n\u001b[1;32m    906\u001b[0m follow_redirects \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    907\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfollow_redirects\n\u001b[1;32m    908\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(follow_redirects, UseClientDefault)\n\u001b[1;32m    909\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m follow_redirects\n\u001b[1;32m    910\u001b[0m )\n\u001b[1;32m    912\u001b[0m auth \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_request_auth(request, auth)\n\u001b[0;32m--> 914\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_handling_auth\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    915\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    916\u001b[0m \u001b[43m    \u001b[49m\u001b[43mauth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mauth\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    917\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    918\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhistory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    919\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    920\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    921\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m stream:\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/httpx/_client.py:942\u001b[0m, in \u001b[0;36mClient._send_handling_auth\u001b[0;34m(self, request, auth, follow_redirects, history)\u001b[0m\n\u001b[1;32m    939\u001b[0m request \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(auth_flow)\n\u001b[1;32m    941\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 942\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_handling_redirects\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    943\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    944\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    945\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhistory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhistory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    946\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    947\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    948\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/httpx/_client.py:979\u001b[0m, in \u001b[0;36mClient._send_handling_redirects\u001b[0;34m(self, request, follow_redirects, history)\u001b[0m\n\u001b[1;32m    976\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_event_hooks[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrequest\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[1;32m    977\u001b[0m     hook(request)\n\u001b[0;32m--> 979\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_single_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    980\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    981\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_event_hooks[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresponse\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/httpx/_client.py:1015\u001b[0m, in \u001b[0;36mClient._send_single_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m   1010\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m   1011\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAttempted to send an async request with a sync Client instance.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1012\u001b[0m     )\n\u001b[1;32m   1014\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m request_context(request\u001b[38;5;241m=\u001b[39mrequest):\n\u001b[0;32m-> 1015\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mtransport\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1017\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response\u001b[38;5;241m.\u001b[39mstream, SyncByteStream)\n\u001b[1;32m   1019\u001b[0m response\u001b[38;5;241m.\u001b[39mrequest \u001b[38;5;241m=\u001b[39m request\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/httpx/_transports/default.py:233\u001b[0m, in \u001b[0;36mHTTPTransport.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    220\u001b[0m req \u001b[38;5;241m=\u001b[39m httpcore\u001b[38;5;241m.\u001b[39mRequest(\n\u001b[1;32m    221\u001b[0m     method\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mmethod,\n\u001b[1;32m    222\u001b[0m     url\u001b[38;5;241m=\u001b[39mhttpcore\u001b[38;5;241m.\u001b[39mURL(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    230\u001b[0m     extensions\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mextensions,\n\u001b[1;32m    231\u001b[0m )\n\u001b[1;32m    232\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m map_httpcore_exceptions():\n\u001b[0;32m--> 233\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_pool\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    235\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(resp\u001b[38;5;241m.\u001b[39mstream, typing\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[1;32m    237\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m Response(\n\u001b[1;32m    238\u001b[0m     status_code\u001b[38;5;241m=\u001b[39mresp\u001b[38;5;241m.\u001b[39mstatus,\n\u001b[1;32m    239\u001b[0m     headers\u001b[38;5;241m=\u001b[39mresp\u001b[38;5;241m.\u001b[39mheaders,\n\u001b[1;32m    240\u001b[0m     stream\u001b[38;5;241m=\u001b[39mResponseStream(resp\u001b[38;5;241m.\u001b[39mstream),\n\u001b[1;32m    241\u001b[0m     extensions\u001b[38;5;241m=\u001b[39mresp\u001b[38;5;241m.\u001b[39mextensions,\n\u001b[1;32m    242\u001b[0m )\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/httpcore/_sync/connection_pool.py:216\u001b[0m, in \u001b[0;36mConnectionPool.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    213\u001b[0m         closing \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_assign_requests_to_connections()\n\u001b[1;32m    215\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_close_connections(closing)\n\u001b[0;32m--> 216\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    218\u001b[0m \u001b[38;5;66;03m# Return the response. Note that in this case we still have to manage\u001b[39;00m\n\u001b[1;32m    219\u001b[0m \u001b[38;5;66;03m# the point at which the response is closed.\u001b[39;00m\n\u001b[1;32m    220\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response\u001b[38;5;241m.\u001b[39mstream, Iterable)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/httpcore/_sync/connection_pool.py:196\u001b[0m, in \u001b[0;36mConnectionPool.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    192\u001b[0m connection \u001b[38;5;241m=\u001b[39m pool_request\u001b[38;5;241m.\u001b[39mwait_for_connection(timeout\u001b[38;5;241m=\u001b[39mtimeout)\n\u001b[1;32m    194\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    195\u001b[0m     \u001b[38;5;66;03m# Send the request on the assigned connection.\u001b[39;00m\n\u001b[0;32m--> 196\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mconnection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    197\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpool_request\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\n\u001b[1;32m    198\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    199\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ConnectionNotAvailable:\n\u001b[1;32m    200\u001b[0m     \u001b[38;5;66;03m# In some cases a connection may initially be available to\u001b[39;00m\n\u001b[1;32m    201\u001b[0m     \u001b[38;5;66;03m# handle a request, but then become unavailable.\u001b[39;00m\n\u001b[1;32m    202\u001b[0m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m    203\u001b[0m     \u001b[38;5;66;03m# In this case we clear the connection and try again.\u001b[39;00m\n\u001b[1;32m    204\u001b[0m     pool_request\u001b[38;5;241m.\u001b[39mclear_connection()\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/httpcore/_sync/connection.py:101\u001b[0m, in \u001b[0;36mHTTPConnection.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_connect_failed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m     99\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc\n\u001b[0;32m--> 101\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_connection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/httpcore/_sync/http11.py:143\u001b[0m, in \u001b[0;36mHTTP11Connection.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    141\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m Trace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresponse_closed\u001b[39m\u001b[38;5;124m\"\u001b[39m, logger, request) \u001b[38;5;28;01mas\u001b[39;00m trace:\n\u001b[1;32m    142\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_response_closed()\n\u001b[0;32m--> 143\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exc\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/httpcore/_sync/http11.py:113\u001b[0m, in \u001b[0;36mHTTP11Connection.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    102\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m    104\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m Trace(\n\u001b[1;32m    105\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreceive_response_headers\u001b[39m\u001b[38;5;124m\"\u001b[39m, logger, request, kwargs\n\u001b[1;32m    106\u001b[0m ) \u001b[38;5;28;01mas\u001b[39;00m trace:\n\u001b[1;32m    107\u001b[0m     (\n\u001b[1;32m    108\u001b[0m         http_version,\n\u001b[1;32m    109\u001b[0m         status,\n\u001b[1;32m    110\u001b[0m         reason_phrase,\n\u001b[1;32m    111\u001b[0m         headers,\n\u001b[1;32m    112\u001b[0m         trailing_data,\n\u001b[0;32m--> 113\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_receive_response_headers\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    114\u001b[0m     trace\u001b[38;5;241m.\u001b[39mreturn_value \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    115\u001b[0m         http_version,\n\u001b[1;32m    116\u001b[0m         status,\n\u001b[1;32m    117\u001b[0m         reason_phrase,\n\u001b[1;32m    118\u001b[0m         headers,\n\u001b[1;32m    119\u001b[0m     )\n\u001b[1;32m    121\u001b[0m network_stream \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_network_stream\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/httpcore/_sync/http11.py:186\u001b[0m, in \u001b[0;36mHTTP11Connection._receive_response_headers\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    183\u001b[0m timeout \u001b[38;5;241m=\u001b[39m timeouts\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mread\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    185\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 186\u001b[0m     event \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_receive_event\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    187\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(event, h11\u001b[38;5;241m.\u001b[39mResponse):\n\u001b[1;32m    188\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/httpcore/_sync/http11.py:224\u001b[0m, in \u001b[0;36mHTTP11Connection._receive_event\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    221\u001b[0m     event \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_h11_state\u001b[38;5;241m.\u001b[39mnext_event()\n\u001b[1;32m    223\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m event \u001b[38;5;129;01mis\u001b[39;00m h11\u001b[38;5;241m.\u001b[39mNEED_DATA:\n\u001b[0;32m--> 224\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_network_stream\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    225\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mREAD_NUM_BYTES\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\n\u001b[1;32m    226\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    228\u001b[0m     \u001b[38;5;66;03m# If we feed this case through h11 we'll raise an exception like:\u001b[39;00m\n\u001b[1;32m    229\u001b[0m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m    230\u001b[0m     \u001b[38;5;66;03m#     httpcore.RemoteProtocolError: can't handle event type\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    234\u001b[0m     \u001b[38;5;66;03m# perspective. Instead we handle this case distinctly and treat\u001b[39;00m\n\u001b[1;32m    235\u001b[0m     \u001b[38;5;66;03m# it as a ConnectError.\u001b[39;00m\n\u001b[1;32m    236\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data \u001b[38;5;241m==\u001b[39m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_h11_state\u001b[38;5;241m.\u001b[39mtheir_state \u001b[38;5;241m==\u001b[39m h11\u001b[38;5;241m.\u001b[39mSEND_RESPONSE:\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/httpcore/_backends/sync.py:126\u001b[0m, in \u001b[0;36mSyncStream.read\u001b[0;34m(self, max_bytes, timeout)\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m map_exceptions(exc_map):\n\u001b[1;32m    125\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sock\u001b[38;5;241m.\u001b[39msettimeout(timeout)\n\u001b[0;32m--> 126\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmax_bytes\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/ssl.py:1292\u001b[0m, in \u001b[0;36mSSLSocket.recv\u001b[0;34m(self, buflen, flags)\u001b[0m\n\u001b[1;32m   1288\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m flags \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   1289\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1290\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnon-zero flags not allowed in calls to recv() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[1;32m   1291\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)\n\u001b[0;32m-> 1292\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbuflen\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1293\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1294\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mrecv(buflen, flags)\n","File \u001b[0;32m/opt/conda/lib/python3.10/ssl.py:1165\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1163\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m, buffer)\n\u001b[1;32m   1164\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1165\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sslobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1166\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m SSLError \u001b[38;5;28;01mas\u001b[39;00m x:\n\u001b[1;32m   1167\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m x\u001b[38;5;241m.\u001b[39margs[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m==\u001b[39m SSL_ERROR_EOF \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msuppress_ragged_eofs:\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}],"execution_count":47},{"cell_type":"code","source":"print(df.columns)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-13T15:43:31.975211Z","iopub.execute_input":"2024-11-13T15:43:31.976006Z","iopub.status.idle":"2024-11-13T15:43:31.981156Z","shell.execute_reply.started":"2024-11-13T15:43:31.975965Z","shell.execute_reply":"2024-11-13T15:43:31.980247Z"}},"outputs":[{"name":"stdout","text":"Index(['sid', 'student_code', 'repaired_code', 'feedback',\n       'metacognitive_vector'],\n      dtype='object')\n","output_type":"stream"}],"execution_count":48},{"cell_type":"code","source":"if 'metacognitive_feedback' not in df.columns:\n    df['metacognitive_feedback'] = None","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-13T15:43:50.315113Z","iopub.execute_input":"2024-11-13T15:43:50.315901Z","iopub.status.idle":"2024-11-13T15:43:50.321373Z","shell.execute_reply.started":"2024-11-13T15:43:50.315860Z","shell.execute_reply":"2024-11-13T15:43:50.320403Z"}},"outputs":[],"execution_count":49},{"cell_type":"code","source":"df.columns","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-13T15:43:58.133538Z","iopub.execute_input":"2024-11-13T15:43:58.134222Z","iopub.status.idle":"2024-11-13T15:43:58.140647Z","shell.execute_reply.started":"2024-11-13T15:43:58.134166Z","shell.execute_reply":"2024-11-13T15:43:58.139605Z"}},"outputs":[{"execution_count":50,"output_type":"execute_result","data":{"text/plain":"Index(['sid', 'student_code', 'repaired_code', 'feedback',\n       'metacognitive_vector', 'metacognitive_feedback'],\n      dtype='object')"},"metadata":{}}],"execution_count":50},{"cell_type":"code","source":"final_feedback_list = final_feedback_list[:248]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-13T15:44:31.376010Z","iopub.execute_input":"2024-11-13T15:44:31.376910Z","iopub.status.idle":"2024-11-13T15:44:31.380945Z","shell.execute_reply.started":"2024-11-13T15:44:31.376864Z","shell.execute_reply":"2024-11-13T15:44:31.379992Z"}},"outputs":[],"execution_count":52},{"cell_type":"code","source":"len(data)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-13T15:45:47.713874Z","iopub.execute_input":"2024-11-13T15:45:47.714820Z","iopub.status.idle":"2024-11-13T15:45:47.720199Z","shell.execute_reply.started":"2024-11-13T15:45:47.714778Z","shell.execute_reply":"2024-11-13T15:45:47.719312Z"}},"outputs":[{"execution_count":55,"output_type":"execute_result","data":{"text/plain":"366"},"metadata":{}}],"execution_count":55},{"cell_type":"code","source":"updated_data = data.iloc[:248]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-13T15:47:36.306957Z","iopub.execute_input":"2024-11-13T15:47:36.307881Z","iopub.status.idle":"2024-11-13T15:47:36.312835Z","shell.execute_reply.started":"2024-11-13T15:47:36.307835Z","shell.execute_reply":"2024-11-13T15:47:36.311780Z"}},"outputs":[],"execution_count":56},{"cell_type":"code","source":"len(updated_data)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-13T15:47:39.117923Z","iopub.execute_input":"2024-11-13T15:47:39.118329Z","iopub.status.idle":"2024-11-13T15:47:39.124537Z","shell.execute_reply.started":"2024-11-13T15:47:39.118292Z","shell.execute_reply":"2024-11-13T15:47:39.123606Z"}},"outputs":[{"execution_count":57,"output_type":"execute_result","data":{"text/plain":"248"},"metadata":{}}],"execution_count":57},{"cell_type":"code","source":"updated_df = pd.DataFrame(updated_data)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-13T15:50:05.799217Z","iopub.execute_input":"2024-11-13T15:50:05.800107Z","iopub.status.idle":"2024-11-13T15:50:05.804351Z","shell.execute_reply.started":"2024-11-13T15:50:05.800066Z","shell.execute_reply":"2024-11-13T15:50:05.803411Z"}},"outputs":[],"execution_count":62},{"cell_type":"code","source":"if 'metacognitive_feedback' not in updated_df.columns:\n    df['metacognitive_feedback'] = None","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-13T15:50:50.197871Z","iopub.execute_input":"2024-11-13T15:50:50.198585Z","iopub.status.idle":"2024-11-13T15:50:50.202610Z","shell.execute_reply.started":"2024-11-13T15:50:50.198543Z","shell.execute_reply":"2024-11-13T15:50:50.201702Z"}},"outputs":[],"execution_count":65},{"cell_type":"code","source":"updated_df.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-13T15:51:00.117877Z","iopub.execute_input":"2024-11-13T15:51:00.118518Z","iopub.status.idle":"2024-11-13T15:51:00.131373Z","shell.execute_reply.started":"2024-11-13T15:51:00.118477Z","shell.execute_reply":"2024-11-13T15:51:00.130329Z"}},"outputs":[{"execution_count":66,"output_type":"execute_result","data":{"text/plain":"   sid                                       student_code  \\\n0  1.0  \"\"\" store the final answer in a variable named...   \n1  2.0  \"\"\" store the final answer in a variable named...   \n2  3.0  \"\"\" store the final answer in a variable named...   \n3  4.0  x=eval(input(\"Enter your age:\"))\\ny=str(input(...   \n4  5.0  n = str(input(\"Enter your name:\"))\\na = str(in...   \n\n                                       repaired_code  \\\n0  \"\"\" store the final answer in a variable named...   \n1  \"\"\" store the final answer in a variable named...   \n2  \"\"\" store the final answer in a variable named...   \n3  y = input(\"Enter your name:\")\\nx = eval(input(...   \n4  n = str(input(\"Enter your name:\"))\\na = str(in...   \n\n                                            feedback  \\\n0  [\\n    {\\n    'line_number': 2,\\n    'feedback...   \n1  [\\n    {\\n        'line_number': 4,\\n        '...   \n2  [\\n    {\\n        'line_number': 2,\\n        '...   \n3  [\\n    {\\n        'line_number': 1,\\n        '...   \n4  [\\n    {\\n        'line_number': 3,\\n        '...   \n\n                               metacognitive_vector  \\\n0  [3, 1, 3, 2, 1, 1, 2, 3, 3, 3, 2, 3, 2, 1, 2, 2]   \n1  [3, 3, 1, 3, 1, 1, 2, 2, 2, 3, 3, 3, 1, 2, 1, 3]   \n2  [3, 2, 2, 3, 3, 2, 2, 3, 3, 1, 3, 2, 1, 1, 2, 1]   \n3  [1, 1, 3, 3, 1, 3, 2, 3, 1, 1, 3, 2, 3, 1, 3, 3]   \n4  [2, 1, 2, 2, 3, 2, 3, 1, 1, 1, 2, 1, 1, 1, 2, 2]   \n\n                              metacognitive_feedback  \n0  ### Personalized Feedback for Your Code\\n\\n###...  \n1  ### Personalized Feedback for Improving Coding...  \n2  ### Personalized Feedback\\n\\n#### Understandin...  \n3  ### Personalized Feedback for Improving Coding...  \n4  ### Personalized Feedback for the Student\\n\\n#...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>sid</th>\n      <th>student_code</th>\n      <th>repaired_code</th>\n      <th>feedback</th>\n      <th>metacognitive_vector</th>\n      <th>metacognitive_feedback</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1.0</td>\n      <td>\"\"\" store the final answer in a variable named...</td>\n      <td>\"\"\" store the final answer in a variable named...</td>\n      <td>[\\n    {\\n    'line_number': 2,\\n    'feedback...</td>\n      <td>[3, 1, 3, 2, 1, 1, 2, 3, 3, 3, 2, 3, 2, 1, 2, 2]</td>\n      <td>### Personalized Feedback for Your Code\\n\\n###...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2.0</td>\n      <td>\"\"\" store the final answer in a variable named...</td>\n      <td>\"\"\" store the final answer in a variable named...</td>\n      <td>[\\n    {\\n        'line_number': 4,\\n        '...</td>\n      <td>[3, 3, 1, 3, 1, 1, 2, 2, 2, 3, 3, 3, 1, 2, 1, 3]</td>\n      <td>### Personalized Feedback for Improving Coding...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3.0</td>\n      <td>\"\"\" store the final answer in a variable named...</td>\n      <td>\"\"\" store the final answer in a variable named...</td>\n      <td>[\\n    {\\n        'line_number': 2,\\n        '...</td>\n      <td>[3, 2, 2, 3, 3, 2, 2, 3, 3, 1, 3, 2, 1, 1, 2, 1]</td>\n      <td>### Personalized Feedback\\n\\n#### Understandin...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4.0</td>\n      <td>x=eval(input(\"Enter your age:\"))\\ny=str(input(...</td>\n      <td>y = input(\"Enter your name:\")\\nx = eval(input(...</td>\n      <td>[\\n    {\\n        'line_number': 1,\\n        '...</td>\n      <td>[1, 1, 3, 3, 1, 3, 2, 3, 1, 1, 3, 2, 3, 1, 3, 3]</td>\n      <td>### Personalized Feedback for Improving Coding...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5.0</td>\n      <td>n = str(input(\"Enter your name:\"))\\na = str(in...</td>\n      <td>n = str(input(\"Enter your name:\"))\\na = str(in...</td>\n      <td>[\\n    {\\n        'line_number': 3,\\n        '...</td>\n      <td>[2, 1, 2, 2, 3, 2, 3, 1, 1, 1, 2, 1, 1, 1, 2, 2]</td>\n      <td>### Personalized Feedback for the Student\\n\\n#...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":66},{"cell_type":"code","source":"# Add final feedback to the DataFrame\nupdated_df['metacognitive_feedback'] = final_feedback_list","metadata":{"_uuid":"2cba4aa5-ad4e-47e3-939f-c9ae182b73ef","_cell_guid":"0c40f999-14e1-44d3-8454-736061357ea9","trusted":true,"execution":{"iopub.status.busy":"2024-11-13T15:50:14.357551Z","iopub.execute_input":"2024-11-13T15:50:14.358413Z","iopub.status.idle":"2024-11-13T15:50:14.362713Z","shell.execute_reply.started":"2024-11-13T15:50:14.358373Z","shell.execute_reply":"2024-11-13T15:50:14.361715Z"}},"outputs":[],"execution_count":63},{"cell_type":"code","source":"# df['metacognitive_feedback'] = df.apply(generate_metacognitive_feedback, axis=1)","metadata":{"_uuid":"a604eaf7-dcb2-4b23-9d7f-b792e95dce3f","_cell_guid":"9efeddb6-0909-4c5f-b8d2-fb2004a06f62","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"updated_df.to_csv('metacognitive_feedback_data.csv', index=False)","metadata":{"_uuid":"898317b5-cc77-4e7f-833e-eac1c12defa0","_cell_guid":"0d817dd9-4405-4f5e-8c31-5acf2849a628","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-11-13T15:51:16.438478Z","iopub.execute_input":"2024-11-13T15:51:16.439149Z","iopub.status.idle":"2024-11-13T15:51:16.513143Z","shell.execute_reply.started":"2024-11-13T15:51:16.439104Z","shell.execute_reply":"2024-11-13T15:51:16.512350Z"}},"outputs":[],"execution_count":67},{"cell_type":"code","source":"df.to_csv(\"metacognitive_feedback_dataset.csv\", index=False)","metadata":{"_uuid":"5e17f015-45c3-4872-a67f-6867be254a0e","_cell_guid":"efdf2a5f-c544-4894-b413-00d2214244fe","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-11-13T12:58:58.769593Z","iopub.status.idle":"2024-11-13T12:58:58.769948Z","shell.execute_reply.started":"2024-11-13T12:58:58.769773Z","shell.execute_reply":"2024-11-13T12:58:58.769791Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# LORA Finetuning","metadata":{"_uuid":"a023a862-9b00-4f82-855a-71df1f920e09","_cell_guid":"d3c2c61a-2c8f-4205-af26-2c960c0c9c3d","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"","metadata":{"_uuid":"0a058457-684b-41e3-8c5a-baf5bd845ec0","_cell_guid":"c1c72b97-43da-4d11-9140-837f5dae6c69","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null}]}