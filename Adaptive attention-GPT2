{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":10048507,"sourceType":"datasetVersion","datasetId":6190931}],"dockerImageVersionId":30804,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"4a407760-fece-43e3-83f0-258295fc1289","_cell_guid":"bce0f255-1c74-4800-874e-e0a0d21c6c65","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-12-17T03:18:55.174808Z","iopub.execute_input":"2024-12-17T03:18:55.175074Z","iopub.status.idle":"2024-12-17T03:18:56.150318Z","shell.execute_reply.started":"2024-12-17T03:18:55.175046Z","shell.execute_reply":"2024-12-17T03:18:56.149365Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/modified-dataset/modified_dataset.csv\n","output_type":"stream"}],"execution_count":1},{"cell_type":"markdown","source":"# Import libraries.","metadata":{"_uuid":"c86ca820-e375-440f-8ad6-e6b4bbaff0a0","_cell_guid":"c09d0da7-12e6-455d-b8b9-bd6197e9c237","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"pip install transformers torch","metadata":{"_uuid":"52d993c3-bed9-4d4a-a6e5-50d60b95de42","_cell_guid":"505ee843-a99c-438e-b45a-2f85e8286c43","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-12-17T03:19:25.595370Z","iopub.execute_input":"2024-12-17T03:19:25.595698Z","iopub.status.idle":"2024-12-17T03:19:34.780216Z","shell.execute_reply.started":"2024-12-17T03:19:25.595668Z","shell.execute_reply":"2024-12-17T03:19:34.778995Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.46.3)\nRequirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (2.4.0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers) (3.15.1)\nRequirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.26.2)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (6.0.2)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2024.5.15)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers) (2.32.3)\nRequirement already satisfied: tokenizers<0.21,>=0.20 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.20.3)\nRequirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.4.5)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers) (4.66.4)\nRequirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/lib/python3.10/site-packages (from torch) (4.12.2)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch) (1.13.3)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch) (3.3)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch) (3.1.4)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch) (2024.6.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers) (3.1.2)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch) (2.1.5)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2024.6.2)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch) (1.3.0)\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"import torch\nfrom torch import nn\nfrom torch.optim import Adam\nfrom torch.utils.data import DataLoader, TensorDataset\nfrom transformers import AutoModel, AutoTokenizer, GPT2Model","metadata":{"_uuid":"54c0ca1b-e865-4607-b7ea-f6b5f55e1ae3","_cell_guid":"82066fba-f007-4733-9e9f-6890e813fc35","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-12-17T03:19:34.782378Z","iopub.execute_input":"2024-12-17T03:19:34.782789Z","iopub.status.idle":"2024-12-17T03:19:49.552439Z","shell.execute_reply.started":"2024-12-17T03:19:34.782745Z","shell.execute_reply":"2024-12-17T03:19:49.551684Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")","metadata":{"_uuid":"abd85071-a8e0-4085-8807-5f20f02b96bb","_cell_guid":"6d660b0a-145b-40be-a319-a80a63ae5a8e","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2024-12-17T03:19:49.553514Z","iopub.execute_input":"2024-12-17T03:19:49.554134Z","iopub.status.idle":"2024-12-17T03:19:49.638221Z","shell.execute_reply.started":"2024-12-17T03:19:49.554093Z","shell.execute_reply":"2024-12-17T03:19:49.637160Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"device","metadata":{"_uuid":"476e590d-eb56-4ce5-b4a2-4180bd480487","_cell_guid":"a7335a65-4e7d-413e-b0f7-b564dc5f7c78","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2024-12-17T03:19:49.640445Z","iopub.execute_input":"2024-12-17T03:19:49.640886Z","iopub.status.idle":"2024-12-17T03:19:49.663723Z","shell.execute_reply.started":"2024-12-17T03:19:49.640836Z","shell.execute_reply":"2024-12-17T03:19:49.662940Z"},"jupyter":{"outputs_hidden":false}},"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"device(type='cuda')"},"metadata":{}}],"execution_count":5},{"cell_type":"markdown","source":"# Models initialization and tokenizations","metadata":{"_uuid":"396fe6e6-fef5-4616-9ce8-259b587e3ecd","_cell_guid":"d7275979-13ad-4bfe-aaa2-6b9bd8294f2e","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"model_name_encoder = \"bert-base-uncased\"","metadata":{"_uuid":"690570be-1c5b-4a40-81ab-d6afaed6ca93","_cell_guid":"2cd89c4a-ee79-4cfb-a64e-9412a9120f60","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-12-17T03:19:49.664679Z","iopub.execute_input":"2024-12-17T03:19:49.664913Z","iopub.status.idle":"2024-12-17T03:19:49.671719Z","shell.execute_reply.started":"2024-12-17T03:19:49.664874Z","shell.execute_reply":"2024-12-17T03:19:49.671011Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"context_encoder = AutoModel.from_pretrained(model_name_encoder)\n#this same encoder will be used as the persona encoder but with a linear projection of 16->768","metadata":{"_uuid":"e32d4fd7-1858-407a-915d-3d3cd08ef64a","_cell_guid":"41d207bd-4d33-45f7-8d80-a7b24aa5edf2","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2024-12-17T03:19:53.375926Z","iopub.execute_input":"2024-12-17T03:19:53.376492Z","iopub.status.idle":"2024-12-17T03:19:56.159076Z","shell.execute_reply.started":"2024-12-17T03:19:53.376452Z","shell.execute_reply":"2024-12-17T03:19:56.158171Z"},"jupyter":{"outputs_hidden":false}},"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0ec4b77b9368481ba31b5aa0c3ef1c7d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9b699a8b27cc4353acaecc08a2204032"}},"metadata":{}}],"execution_count":7},{"cell_type":"code","source":"context_encoder","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-17T03:19:56.160351Z","iopub.execute_input":"2024-12-17T03:19:56.160674Z","iopub.status.idle":"2024-12-17T03:19:56.167507Z","shell.execute_reply.started":"2024-12-17T03:19:56.160646Z","shell.execute_reply":"2024-12-17T03:19:56.166616Z"}},"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"BertModel(\n  (embeddings): BertEmbeddings(\n    (word_embeddings): Embedding(30522, 768, padding_idx=0)\n    (position_embeddings): Embedding(512, 768)\n    (token_type_embeddings): Embedding(2, 768)\n    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n    (dropout): Dropout(p=0.1, inplace=False)\n  )\n  (encoder): BertEncoder(\n    (layer): ModuleList(\n      (0-11): 12 x BertLayer(\n        (attention): BertAttention(\n          (self): BertSdpaSelfAttention(\n            (query): Linear(in_features=768, out_features=768, bias=True)\n            (key): Linear(in_features=768, out_features=768, bias=True)\n            (value): Linear(in_features=768, out_features=768, bias=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (output): BertSelfOutput(\n            (dense): Linear(in_features=768, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (intermediate): BertIntermediate(\n          (dense): Linear(in_features=768, out_features=3072, bias=True)\n          (intermediate_act_fn): GELUActivation()\n        )\n        (output): BertOutput(\n          (dense): Linear(in_features=3072, out_features=768, bias=True)\n          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n          (dropout): Dropout(p=0.1, inplace=False)\n        )\n      )\n    )\n  )\n  (pooler): BertPooler(\n    (dense): Linear(in_features=768, out_features=768, bias=True)\n    (activation): Tanh()\n  )\n)"},"metadata":{}}],"execution_count":8},{"cell_type":"code","source":"decoder = GPT2Model.from_pretrained(\"gpt2\")","metadata":{"_uuid":"f1b6665f-5aaf-419d-8cb6-cc07900f9ec8","_cell_guid":"70a7e943-ee33-4ca5-8a75-8cf1a6c20387","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-12-17T03:20:20.675775Z","iopub.execute_input":"2024-12-17T03:20:20.676445Z","iopub.status.idle":"2024-12-17T03:20:23.687234Z","shell.execute_reply.started":"2024-12-17T03:20:20.676412Z","shell.execute_reply":"2024-12-17T03:20:23.686276Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1c2d3a507a8c46b0afa90cfbbce26848"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/548M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4860bfdf5bc24e829edc7cb92118de65"}},"metadata":{}}],"execution_count":9},{"cell_type":"code","source":"decoder","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-17T03:20:23.688655Z","iopub.execute_input":"2024-12-17T03:20:23.688926Z","iopub.status.idle":"2024-12-17T03:20:23.695122Z","shell.execute_reply.started":"2024-12-17T03:20:23.688900Z","shell.execute_reply":"2024-12-17T03:20:23.694216Z"}},"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"GPT2Model(\n  (wte): Embedding(50257, 768)\n  (wpe): Embedding(1024, 768)\n  (drop): Dropout(p=0.1, inplace=False)\n  (h): ModuleList(\n    (0-11): 12 x GPT2Block(\n      (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n      (attn): GPT2SdpaAttention(\n        (c_attn): Conv1D(nf=2304, nx=768)\n        (c_proj): Conv1D(nf=768, nx=768)\n        (attn_dropout): Dropout(p=0.1, inplace=False)\n        (resid_dropout): Dropout(p=0.1, inplace=False)\n      )\n      (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n      (mlp): GPT2MLP(\n        (c_fc): Conv1D(nf=3072, nx=768)\n        (c_proj): Conv1D(nf=768, nx=3072)\n        (act): NewGELUActivation()\n        (dropout): Dropout(p=0.1, inplace=False)\n      )\n    )\n  )\n  (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n)"},"metadata":{}}],"execution_count":10},{"cell_type":"code","source":"decoder.resize_token_embeddings(decoder.config.vocab_size)","metadata":{"_uuid":"f5419cd6-38c2-4241-a363-61cbbef96ac2","_cell_guid":"da3cb94a-d8dc-4fca-a856-ec8e07d977ce","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-12-17T03:20:33.760098Z","iopub.execute_input":"2024-12-17T03:20:33.760449Z","iopub.status.idle":"2024-12-17T03:20:33.766945Z","shell.execute_reply.started":"2024-12-17T03:20:33.760416Z","shell.execute_reply":"2024-12-17T03:20:33.765990Z"}},"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"Embedding(50257, 768)"},"metadata":{}}],"execution_count":11},{"cell_type":"code","source":"# Tokenizer\ntokenizer_encoder = AutoTokenizer.from_pretrained(model_name_encoder)","metadata":{"_uuid":"71021b85-ce78-4ad0-b401-7d42499e57e4","_cell_guid":"00345d6d-d9b9-4a69-91b9-acbcbae9b7bc","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-12-17T03:20:36.795476Z","iopub.execute_input":"2024-12-17T03:20:36.795805Z","iopub.status.idle":"2024-12-17T03:20:37.348150Z","shell.execute_reply.started":"2024-12-17T03:20:36.795774Z","shell.execute_reply":"2024-12-17T03:20:37.347331Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d8064a30547b4cea98d0f1def8388c99"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"34d3541d35b84fa987ee5df8c3d1c49c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4502d6cf52dd4885a35033bcb1091268"}},"metadata":{}}],"execution_count":12},{"cell_type":"code","source":"tokenizer_encoder","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-17T03:26:17.376069Z","iopub.execute_input":"2024-12-17T03:26:17.376428Z","iopub.status.idle":"2024-12-17T03:26:17.382803Z","shell.execute_reply.started":"2024-12-17T03:26:17.376396Z","shell.execute_reply":"2024-12-17T03:26:17.381778Z"}},"outputs":[{"execution_count":36,"output_type":"execute_result","data":{"text/plain":"BertTokenizerFast(name_or_path='bert-base-uncased', vocab_size=30522, model_max_length=512, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'}, clean_up_tokenization_spaces=False),  added_tokens_decoder={\n\t0: AddedToken(\"[PAD]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t100: AddedToken(\"[UNK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t101: AddedToken(\"[CLS]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t102: AddedToken(\"[SEP]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t103: AddedToken(\"[MASK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n}"},"metadata":{}}],"execution_count":36},{"cell_type":"code","source":"tokenizer_decoder = AutoTokenizer.from_pretrained(\"gpt2\")","metadata":{"_uuid":"2866246d-8def-4bca-9dfc-26c760d8c276","_cell_guid":"4f2fef67-ea28-4d83-bf4f-59f65d43ed79","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2024-12-17T03:20:40.265321Z","iopub.execute_input":"2024-12-17T03:20:40.265676Z","iopub.status.idle":"2024-12-17T03:20:41.163512Z","shell.execute_reply.started":"2024-12-17T03:20:40.265646Z","shell.execute_reply":"2024-12-17T03:20:41.162824Z"},"jupyter":{"outputs_hidden":false}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f0470df8eeed4631a49174c4a2c2c11d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"886799a26a8f4c709152cec4978dd863"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c20cadd962d9404e9b9eb87577df6471"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fa64d2e154fa4d93afa8d22a211aae8b"}},"metadata":{}}],"execution_count":13},{"cell_type":"code","source":"# Set padding token to eos_token for GPT-2\ntokenizer_decoder.pad_token = tokenizer_decoder.eos_token","metadata":{"_uuid":"2349b441-e524-4069-b1c4-477ede9e4681","_cell_guid":"04eed121-e7f5-4cd3-afc9-75fb658dcd5f","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2024-12-17T03:20:43.185513Z","iopub.execute_input":"2024-12-17T03:20:43.185844Z","iopub.status.idle":"2024-12-17T03:20:43.190316Z","shell.execute_reply.started":"2024-12-17T03:20:43.185814Z","shell.execute_reply":"2024-12-17T03:20:43.189179Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"# Learnable projection layer for metacognitive profile\nprofile_projection = nn.Linear(16, context_encoder.config.hidden_size)","metadata":{"_uuid":"3516c118-4152-4f72-aec3-6e00babf7594","_cell_guid":"d3ff658b-dd0c-4cb6-8eb9-d03179b63c7a","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-12-17T03:20:46.235931Z","iopub.execute_input":"2024-12-17T03:20:46.236867Z","iopub.status.idle":"2024-12-17T03:20:46.244759Z","shell.execute_reply.started":"2024-12-17T03:20:46.236819Z","shell.execute_reply":"2024-12-17T03:20:46.243891Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"profile_projection","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-17T03:20:49.345328Z","iopub.execute_input":"2024-12-17T03:20:49.345672Z","iopub.status.idle":"2024-12-17T03:20:49.350971Z","shell.execute_reply.started":"2024-12-17T03:20:49.345643Z","shell.execute_reply":"2024-12-17T03:20:49.350128Z"}},"outputs":[{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"Linear(in_features=16, out_features=768, bias=True)"},"metadata":{}}],"execution_count":16},{"cell_type":"markdown","source":"# Defining the PAA layers and Model","metadata":{"_uuid":"5da23592-dc68-471c-b4c0-440668a52ead","_cell_guid":"6e822047-2050-4fcd-9a16-ac15230bec27","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"class PAALayer(nn.Module):\n    def __init__(self, hidden_size):\n        super(PAALayer, self).__init__()\n        self.cross_attn = nn.MultiheadAttention(hidden_size, num_heads=8)\n        self.sigmoid = nn.Sigmoid()\n        self.linear = nn.Linear(hidden_size * 2, hidden_size)\n\n    def forward(self, persona_hidden, context_hidden, decoder_hidden, tau):\n        c1, _ = self.cross_attn(decoder_hidden, persona_hidden, persona_hidden)\n        c2, _ = self.cross_attn(decoder_hidden, context_hidden, context_hidden)\n        \n        # Adaptive weight calculation\n        w1 = self.sigmoid(self.linear(torch.cat((c1, decoder_hidden), dim=-1)))\n        w2 = 1 - w1\n\n        # Mask creation\n        m1 = torch.where(w1 > tau, 0, 1)\n        m2 = torch.where(w1 < 1 - tau, 0, 1)\n\n        # Weighted summation with masks\n        paa_output = w1 * m1 * c1 + w2 * m2 * c2 + decoder_hidden\n        return paa_output","metadata":{"_uuid":"b23db8c0-6492-4b62-bb1b-308e58de78a8","_cell_guid":"069d098b-564e-47fb-bd89-f91b70ae2944","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-12-17T03:20:54.715771Z","iopub.execute_input":"2024-12-17T03:20:54.716130Z","iopub.status.idle":"2024-12-17T03:20:54.722624Z","shell.execute_reply.started":"2024-12-17T03:20:54.716099Z","shell.execute_reply":"2024-12-17T03:20:54.721703Z"}},"outputs":[],"execution_count":17},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nclass PAA_Model(nn.Module):\n    def __init__(self, context_encoder, decoder, profile_projection, paa_layer):\n        super(PAA_Model, self).__init__()\n        self.context_encoder = context_encoder\n        self.decoder = decoder\n        self.profile_projection = profile_projection\n        self.paa_layer = paa_layer\n        self.loss_fn = nn.CrossEntropyLoss()\n\n    def forward(self, context_tokens, target_tokens, profile_vector, tau):\n        # Encode context\n        context_hidden = self.context_encoder(**context_tokens).last_hidden_state\n        print(f\"context_hidden shape: {context_hidden.shape}\")\n\n        # Project metacognitive profile\n        projected_profile = self.profile_projection(profile_vector).unsqueeze(1)\n        print(f\"projected profile shape: {projected_profile.shape}\")\n\n        # Expand persona representation\n        persona_hidden = projected_profile.expand(-1, context_hidden.size(1), -1)\n        print(f\"persona_hidden shape: {persona_hidden.shape}\")\n\n        # Resize or pad persona_hidden and context_hidden to match decoder_hidden length\n        target_length = target_tokens['input_ids'].shape[1]  # Match target sequence length (e.g., decoder_hidden length)\n        context_hidden_resized = self.resize_sequence(context_hidden, target_length)\n        persona_hidden_resized = self.resize_sequence(persona_hidden, target_length)\n\n        print(f\"Resized context_hidden shape: {context_hidden_resized.shape}\")\n        print(f\"Resized persona_hidden shape: {persona_hidden_resized.shape}\")\n\n        # Decoder's output\n        decoder_hidden = self.decoder(**target_tokens).last_hidden_state\n        print(f\"decoder_hidden shape: {decoder_hidden.shape}\")\n\n        # Apply PAA\n        paa_output = self.paa_layer(persona_hidden_resized, context_hidden_resized, decoder_hidden, tau)\n\n        # No softmax here, CrossEntropyLoss expects raw logits\n        logits = paa_output\n        target = target_tokens['input_ids'][:, 1:].contiguous().view(-1)  # Flatten target tokens\n        print(f\"logits shape: {logits.shape}\")\n        print(f\"target shape: {target.shape}\")\n\n        # Ensure logits and target have matching batch size\n        logits = logits.view(-1, logits.size(-1))  # Shape: (batch_size * seq_len, vocab_size)\n\n        assert logits.size(0) == target.size(0), f\"Batch size mismatch: logits batch size {logits.size(0)} vs target batch size {target.size(0)}\"\n\n        # Calculate loss\n        loss = self.loss_fn(logits, target)\n        return loss\n\n    def resize_sequence(self, tensor, target_length):\n        \"\"\"\n        Resize tensor sequence to the target length using padding or interpolation.\n        This method can be adjusted to use either padding or interpolation as per the requirement.\n        \"\"\"\n        current_length = tensor.size(1)\n        if current_length < target_length:\n            # Padding case\n            padding_length = target_length - current_length\n            return F.pad(tensor, (0, 0, 0, padding_length), \"constant\", 0)\n        elif current_length > target_length:\n            # Truncation case\n            return tensor[:, :target_length, :]\n        else:\n            return tensor  # No change if lengths match\n","metadata":{"_uuid":"38c60efb-a170-4407-9358-c4f0672f0730","_cell_guid":"bf4ca38d-3ddf-495f-93c0-451889c297d7","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-12-17T03:20:59.780648Z","iopub.execute_input":"2024-12-17T03:20:59.781367Z","iopub.status.idle":"2024-12-17T03:20:59.790972Z","shell.execute_reply.started":"2024-12-17T03:20:59.781336Z","shell.execute_reply":"2024-12-17T03:20:59.789941Z"}},"outputs":[],"execution_count":18},{"cell_type":"markdown","source":"# Model and optimizer","metadata":{"_uuid":"a65a11be-0a5d-436c-bada-99dfa399bf9e","_cell_guid":"88f012aa-6217-45b6-907c-f47691a5c9cb","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"paa_layer = PAALayer(context_encoder.config.hidden_size)","metadata":{"_uuid":"95f28036-1e0a-41b9-a776-deaabb4f0877","_cell_guid":"3a29e610-71e5-4402-8a5a-d0a95556a1ce","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-12-17T03:21:03.265181Z","iopub.execute_input":"2024-12-17T03:21:03.265531Z","iopub.status.idle":"2024-12-17T03:21:03.295814Z","shell.execute_reply.started":"2024-12-17T03:21:03.265499Z","shell.execute_reply":"2024-12-17T03:21:03.295214Z"}},"outputs":[],"execution_count":19},{"cell_type":"code","source":"paa_layer","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-17T03:21:05.705134Z","iopub.execute_input":"2024-12-17T03:21:05.705435Z","iopub.status.idle":"2024-12-17T03:21:05.710899Z","shell.execute_reply.started":"2024-12-17T03:21:05.705408Z","shell.execute_reply":"2024-12-17T03:21:05.710062Z"}},"outputs":[{"execution_count":20,"output_type":"execute_result","data":{"text/plain":"PAALayer(\n  (cross_attn): MultiheadAttention(\n    (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n  )\n  (sigmoid): Sigmoid()\n  (linear): Linear(in_features=1536, out_features=768, bias=True)\n)"},"metadata":{}}],"execution_count":20},{"cell_type":"code","source":"model = PAA_Model(context_encoder, decoder, profile_projection, paa_layer).to(device)","metadata":{"_uuid":"c586fdef-8f52-4691-96c2-2f4d1781fa57","_cell_guid":"35577727-423a-4058-9dcd-b1678cabe6d4","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-12-17T03:21:26.015247Z","iopub.execute_input":"2024-12-17T03:21:26.015551Z","iopub.status.idle":"2024-12-17T03:21:26.502035Z","shell.execute_reply.started":"2024-12-17T03:21:26.015525Z","shell.execute_reply":"2024-12-17T03:21:26.501334Z"}},"outputs":[],"execution_count":21},{"cell_type":"code","source":"model","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-17T03:21:28.750644Z","iopub.execute_input":"2024-12-17T03:21:28.750929Z","iopub.status.idle":"2024-12-17T03:21:28.757993Z","shell.execute_reply.started":"2024-12-17T03:21:28.750904Z","shell.execute_reply":"2024-12-17T03:21:28.757152Z"}},"outputs":[{"execution_count":22,"output_type":"execute_result","data":{"text/plain":"PAA_Model(\n  (context_encoder): BertModel(\n    (embeddings): BertEmbeddings(\n      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n      (position_embeddings): Embedding(512, 768)\n      (token_type_embeddings): Embedding(2, 768)\n      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n      (dropout): Dropout(p=0.1, inplace=False)\n    )\n    (encoder): BertEncoder(\n      (layer): ModuleList(\n        (0-11): 12 x BertLayer(\n          (attention): BertAttention(\n            (self): BertSdpaSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n    )\n    (pooler): BertPooler(\n      (dense): Linear(in_features=768, out_features=768, bias=True)\n      (activation): Tanh()\n    )\n  )\n  (decoder): GPT2Model(\n    (wte): Embedding(50257, 768)\n    (wpe): Embedding(1024, 768)\n    (drop): Dropout(p=0.1, inplace=False)\n    (h): ModuleList(\n      (0-11): 12 x GPT2Block(\n        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n        (attn): GPT2SdpaAttention(\n          (c_attn): Conv1D(nf=2304, nx=768)\n          (c_proj): Conv1D(nf=768, nx=768)\n          (attn_dropout): Dropout(p=0.1, inplace=False)\n          (resid_dropout): Dropout(p=0.1, inplace=False)\n        )\n        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n        (mlp): GPT2MLP(\n          (c_fc): Conv1D(nf=3072, nx=768)\n          (c_proj): Conv1D(nf=768, nx=3072)\n          (act): NewGELUActivation()\n          (dropout): Dropout(p=0.1, inplace=False)\n        )\n      )\n    )\n    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n  )\n  (profile_projection): Linear(in_features=16, out_features=768, bias=True)\n  (paa_layer): PAALayer(\n    (cross_attn): MultiheadAttention(\n      (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n    )\n    (sigmoid): Sigmoid()\n    (linear): Linear(in_features=1536, out_features=768, bias=True)\n  )\n  (loss_fn): CrossEntropyLoss()\n)"},"metadata":{}}],"execution_count":22},{"cell_type":"code","source":"optimizer = Adam(model.parameters(), lr=5e-5)","metadata":{"_uuid":"dda16650-0ad9-419e-9079-3655382ce3df","_cell_guid":"e9030db2-ec81-4254-8c73-2dc9a1b05047","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-12-17T03:23:16.496291Z","iopub.execute_input":"2024-12-17T03:23:16.497046Z","iopub.status.idle":"2024-12-17T03:23:16.502307Z","shell.execute_reply.started":"2024-12-17T03:23:16.497014Z","shell.execute_reply":"2024-12-17T03:23:16.501444Z"}},"outputs":[],"execution_count":23},{"cell_type":"markdown","source":"# Dataset preparation","metadata":{"_uuid":"d4c7d311-5619-4ee4-9ebd-1fed8add3c77","_cell_guid":"0992d609-3994-4dc7-9d34-addfa6b3f52c","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"file_path = \"/kaggle/input/modified-dataset/modified_dataset.csv\"\ndf = pd.read_csv(file_path)","metadata":{"_uuid":"0f0e332c-7410-47ef-ab17-fb4d76318b9f","_cell_guid":"57dd7de2-47b0-48a3-a353-3f2834ff6fa3","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-12-17T03:23:19.435811Z","iopub.execute_input":"2024-12-17T03:23:19.436398Z","iopub.status.idle":"2024-12-17T03:23:19.474905Z","shell.execute_reply.started":"2024-12-17T03:23:19.436363Z","shell.execute_reply":"2024-12-17T03:23:19.474186Z"}},"outputs":[],"execution_count":24},{"cell_type":"code","source":"df.head(5)","metadata":{"_uuid":"aabe0e36-21e0-4cb7-83e7-7288c442cd35","_cell_guid":"5188d244-16c3-4497-998a-b5b736a2a798","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-12-17T03:23:28.830513Z","iopub.execute_input":"2024-12-17T03:23:28.830855Z","iopub.status.idle":"2024-12-17T03:23:28.842055Z","shell.execute_reply.started":"2024-12-17T03:23:28.830824Z","shell.execute_reply":"2024-12-17T03:23:28.840888Z"}},"outputs":[{"execution_count":26,"output_type":"execute_result","data":{"text/plain":"                                         description  \\\n0  Create a Python program that performs the foll...   \n1  Create a Python program that accomplishes the ...   \n2  Create a Python program that accomplishes the ...   \n3  Create a Python program that accomplishes the ...   \n4  Create a Python program that accomplishes the ...   \n\n                                        student_code  \\\n0  \"\"\" store the final answer in a variable named...   \n1  \"\"\" store the final answer in a variable named...   \n2  \"\"\" store the final answer in a variable named...   \n3  x=eval(input(\"Enter your age:\"))\\ny=str(input(...   \n4  n = str(input(\"Enter your name:\"))\\na = str(in...   \n\n                                            feedback  \\\n0  [\\n    {\\n    'line_number': 2,\\n    'feedback...   \n1  [\\n    {\\n        'line_number': 4,\\n        '...   \n2  [\\n    {\\n        'line_number': 2,\\n        '...   \n3  [\\n    {\\n        'line_number': 1,\\n        '...   \n4  [\\n    {\\n        'line_number': 3,\\n        '...   \n\n                              metacognitive_feedback  \\\n0  It appears that you are almost on the right tr...   \n1  To improve your solution and better align with...   \n2  Based on your approach to the problem, it seem...   \n3  Based on your approach, it seems like you ofte...   \n4  **Metacognitive Feedback**:\\n\\nYou've made a g...   \n\n                              metacognitive_profile  \n0  [2, 1, 3, 3, 2, 3, 2, 1, 3, 1, 1, 3, 2, 1, 2, 1]  \n1  [3, 1, 2, 2, 3, 1, 3, 3, 2, 3, 3, 2, 1, 2, 2, 1]  \n2  [2, 1, 1, 2, 2, 3, 3, 1, 3, 3, 2, 1, 2, 1, 2, 2]  \n3  [1, 3, 1, 3, 1, 3, 2, 3, 2, 3, 3, 2, 3, 2, 3, 2]  \n4  [3, 1, 3, 3, 2, 1, 3, 3, 3, 1, 2, 3, 2, 1, 1, 3]  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>description</th>\n      <th>student_code</th>\n      <th>feedback</th>\n      <th>metacognitive_feedback</th>\n      <th>metacognitive_profile</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Create a Python program that performs the foll...</td>\n      <td>\"\"\" store the final answer in a variable named...</td>\n      <td>[\\n    {\\n    'line_number': 2,\\n    'feedback...</td>\n      <td>It appears that you are almost on the right tr...</td>\n      <td>[2, 1, 3, 3, 2, 3, 2, 1, 3, 1, 1, 3, 2, 1, 2, 1]</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Create a Python program that accomplishes the ...</td>\n      <td>\"\"\" store the final answer in a variable named...</td>\n      <td>[\\n    {\\n        'line_number': 4,\\n        '...</td>\n      <td>To improve your solution and better align with...</td>\n      <td>[3, 1, 2, 2, 3, 1, 3, 3, 2, 3, 3, 2, 1, 2, 2, 1]</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Create a Python program that accomplishes the ...</td>\n      <td>\"\"\" store the final answer in a variable named...</td>\n      <td>[\\n    {\\n        'line_number': 2,\\n        '...</td>\n      <td>Based on your approach to the problem, it seem...</td>\n      <td>[2, 1, 1, 2, 2, 3, 3, 1, 3, 3, 2, 1, 2, 1, 2, 2]</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Create a Python program that accomplishes the ...</td>\n      <td>x=eval(input(\"Enter your age:\"))\\ny=str(input(...</td>\n      <td>[\\n    {\\n        'line_number': 1,\\n        '...</td>\n      <td>Based on your approach, it seems like you ofte...</td>\n      <td>[1, 3, 1, 3, 1, 3, 2, 3, 2, 3, 3, 2, 3, 2, 3, 2]</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Create a Python program that accomplishes the ...</td>\n      <td>n = str(input(\"Enter your name:\"))\\na = str(in...</td>\n      <td>[\\n    {\\n        'line_number': 3,\\n        '...</td>\n      <td>**Metacognitive Feedback**:\\n\\nYou've made a g...</td>\n      <td>[3, 1, 3, 3, 2, 1, 3, 3, 3, 1, 2, 3, 2, 1, 1, 3]</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":26},{"cell_type":"code","source":"len(df)","metadata":{"_uuid":"57da18f5-9229-4275-9174-02d9785d8ec8","_cell_guid":"fc5ba1f8-45ec-41fe-a4bb-135c78158664","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-12-17T03:25:07.656295Z","iopub.execute_input":"2024-12-17T03:25:07.656641Z","iopub.status.idle":"2024-12-17T03:25:07.662314Z","shell.execute_reply.started":"2024-12-17T03:25:07.656610Z","shell.execute_reply":"2024-12-17T03:25:07.661287Z"}},"outputs":[{"execution_count":33,"output_type":"execute_result","data":{"text/plain":"366"},"metadata":{}}],"execution_count":33},{"cell_type":"code","source":"len(list(df['description']))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-17T03:25:44.656848Z","iopub.execute_input":"2024-12-17T03:25:44.657666Z","iopub.status.idle":"2024-12-17T03:25:44.662746Z","shell.execute_reply.started":"2024-12-17T03:25:44.657628Z","shell.execute_reply":"2024-12-17T03:25:44.661923Z"}},"outputs":[{"execution_count":35,"output_type":"execute_result","data":{"text/plain":"366"},"metadata":{}}],"execution_count":35},{"cell_type":"code","source":"import ast\ndef tokenize_data(df, tokenizer_encoder,tokenizer_decoder):\n    context_tokens = tokenizer_encoder(list(df['description']), padding=True, truncation=True, return_tensors=\"pt\")\n    target_tokens = tokenizer_decoder(list(df['metacognitive_feedback']), padding=True, truncation=True, return_tensors=\"pt\")\n    profile_vectors = torch.tensor([ast.literal_eval(profile) for profile in df['metacognitive_profile']], dtype=torch.float)\n    return context_tokens, target_tokens, profile_vectors","metadata":{"_uuid":"00ad70e8-6c81-4935-9250-c56fcaaca482","_cell_guid":"dfd22fe5-a704-40ab-ad2a-88c4a73a9176","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-12-17T03:23:31.896044Z","iopub.execute_input":"2024-12-17T03:23:31.896666Z","iopub.status.idle":"2024-12-17T03:23:31.901631Z","shell.execute_reply.started":"2024-12-17T03:23:31.896632Z","shell.execute_reply":"2024-12-17T03:23:31.900687Z"}},"outputs":[],"execution_count":27},{"cell_type":"code","source":"context_tokens, target_tokens, profile_vectors = tokenize_data(df, tokenizer_encoder,tokenizer_decoder)","metadata":{"_uuid":"09cc8670-66ac-43d3-a6eb-9143cdebd9ed","_cell_guid":"124b3a3d-a23e-4d05-8d66-b95c7d9f37d4","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2024-12-17T03:23:35.760810Z","iopub.execute_input":"2024-12-17T03:23:35.761670Z","iopub.status.idle":"2024-12-17T03:23:36.180240Z","shell.execute_reply.started":"2024-12-17T03:23:35.761631Z","shell.execute_reply":"2024-12-17T03:23:36.179516Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":28},{"cell_type":"code","source":"len(target_tokens)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-17T03:24:22.895921Z","iopub.execute_input":"2024-12-17T03:24:22.896682Z","iopub.status.idle":"2024-12-17T03:24:22.902789Z","shell.execute_reply.started":"2024-12-17T03:24:22.896624Z","shell.execute_reply":"2024-12-17T03:24:22.901713Z"}},"outputs":[{"execution_count":31,"output_type":"execute_result","data":{"text/plain":"2"},"metadata":{}}],"execution_count":31},{"cell_type":"code","source":"profile_vectors","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-17T03:24:37.355597Z","iopub.execute_input":"2024-12-17T03:24:37.355935Z","iopub.status.idle":"2024-12-17T03:24:37.386198Z","shell.execute_reply.started":"2024-12-17T03:24:37.355905Z","shell.execute_reply":"2024-12-17T03:24:37.385211Z"}},"outputs":[{"execution_count":32,"output_type":"execute_result","data":{"text/plain":"tensor([[2., 1., 3.,  ..., 1., 2., 1.],\n        [3., 1., 2.,  ..., 2., 2., 1.],\n        [2., 1., 1.,  ..., 1., 2., 2.],\n        ...,\n        [1., 2., 2.,  ..., 3., 3., 3.],\n        [3., 3., 3.,  ..., 2., 1., 3.],\n        [1., 2., 3.,  ..., 3., 3., 1.]])"},"metadata":{}}],"execution_count":32},{"cell_type":"code","source":"context_tokens = {key: value.to(device) for key, value in context_tokens.items()}\ntarget_tokens = {key: value.to(device) for key, value in target_tokens.items()}\nprofile_vectors = profile_vectors.to(device)","metadata":{"_uuid":"0a6037a1-8120-4f87-98d9-76ba55e7c9d0","_cell_guid":"8875658a-83ea-4932-bc7b-a90825f10a5f","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2024-12-17T03:26:46.460774Z","iopub.execute_input":"2024-12-17T03:26:46.461436Z","iopub.status.idle":"2024-12-17T03:26:46.482051Z","shell.execute_reply.started":"2024-12-17T03:26:46.461397Z","shell.execute_reply":"2024-12-17T03:26:46.481185Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":37},{"cell_type":"code","source":"# Create DataLoader\ntrain_data = TensorDataset(context_tokens['input_ids'], target_tokens['input_ids'], profile_vectors)\ntrain_loader = DataLoader(train_data, batch_size=8, shuffle=True)","metadata":{"_uuid":"1048c9d9-06ea-49e2-b642-c456d6c2655c","_cell_guid":"ec522685-b292-4e50-808a-32d0c5b880a3","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-12-17T03:26:54.280836Z","iopub.execute_input":"2024-12-17T03:26:54.281154Z","iopub.status.idle":"2024-12-17T03:26:54.285616Z","shell.execute_reply.started":"2024-12-17T03:26:54.281127Z","shell.execute_reply":"2024-12-17T03:26:54.284698Z"}},"outputs":[],"execution_count":38},{"cell_type":"markdown","source":"# Training loop","metadata":{"_uuid":"f71ce5bb-0a33-4482-b458-41e5bda33f4b","_cell_guid":"c6c808ad-3f19-40e8-baeb-05e6450d830b","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"model.train()\nnum_epochs = 5\ntau = 0.5\n\nfor epoch in range(num_epochs):\n    total_loss = 0\n    for context_ids, target_ids, profile_vector in train_loader:\n        # Move tensors to the GPU (if available)\n        context_ids = context_ids.to(device)\n        target_ids = target_ids.to(device)\n        profile_vector = profile_vector.to(device)\n\n        optimizer.zero_grad()\n\n        # Prepare input tensors\n        context_tokens = {'input_ids': context_ids, 'attention_mask': context_ids != tokenizer_encoder.pad_token_id}\n        target_tokens = {'input_ids': target_ids, 'attention_mask': target_ids != tokenizer_decoder.pad_token_id}\n\n        # Forward pass through the model\n        loss = model(context_tokens, target_tokens, profile_vector, tau)\n\n        # Backpropagate and update the model\n        loss.backward()\n        optimizer.step()\n        total_loss += loss.item()\n\n    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {total_loss/len(train_loader)}\")","metadata":{"_uuid":"04db2fd9-30da-45ef-a653-44d95a2d6a05","_cell_guid":"c154751d-5f67-47dc-91d8-fc6483a92e69","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-12-17T03:26:58.135783Z","iopub.execute_input":"2024-12-17T03:26:58.136128Z","iopub.status.idle":"2024-12-17T03:27:00.030683Z","shell.execute_reply.started":"2024-12-17T03:26:58.136098Z","shell.execute_reply":"2024-12-17T03:27:00.029527Z"}},"outputs":[{"name":"stdout","text":"context_hidden shape: torch.Size([8, 351, 768])\nprojected profile shape: torch.Size([8, 1, 768])\npersona_hidden shape: torch.Size([8, 351, 768])\nResized context_hidden shape: torch.Size([8, 743, 768])\nResized persona_hidden shape: torch.Size([8, 743, 768])\ndecoder_hidden shape: torch.Size([8, 743, 768])\nlogits shape: torch.Size([8, 743, 768])\ntarget shape: torch.Size([5936])\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)","Cell \u001b[0;32mIn[39], line 20\u001b[0m\n\u001b[1;32m     17\u001b[0m target_tokens \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minput_ids\u001b[39m\u001b[38;5;124m'\u001b[39m: target_ids, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mattention_mask\u001b[39m\u001b[38;5;124m'\u001b[39m: target_ids \u001b[38;5;241m!=\u001b[39m tokenizer_decoder\u001b[38;5;241m.\u001b[39mpad_token_id}\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# Forward pass through the model\u001b[39;00m\n\u001b[0;32m---> 20\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcontext_tokens\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_tokens\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprofile_vector\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtau\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m# Backpropagate and update the model\u001b[39;00m\n\u001b[1;32m     23\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","Cell \u001b[0;32mIn[18], line 51\u001b[0m, in \u001b[0;36mPAA_Model.forward\u001b[0;34m(self, context_tokens, target_tokens, profile_vector, tau)\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;66;03m# Ensure logits and target have matching batch size\u001b[39;00m\n\u001b[1;32m     49\u001b[0m logits \u001b[38;5;241m=\u001b[39m logits\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, logits\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m))  \u001b[38;5;66;03m# Shape: (batch_size * seq_len, vocab_size)\u001b[39;00m\n\u001b[0;32m---> 51\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m logits\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m) \u001b[38;5;241m==\u001b[39m target\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBatch size mismatch: logits batch size \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlogits\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m vs target batch size \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtarget\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     53\u001b[0m \u001b[38;5;66;03m# Calculate loss\u001b[39;00m\n\u001b[1;32m     54\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss_fn(logits, target)\n","\u001b[0;31mAssertionError\u001b[0m: Batch size mismatch: logits batch size 5944 vs target batch size 5936"],"ename":"AssertionError","evalue":"Batch size mismatch: logits batch size 5944 vs target batch size 5936","output_type":"error"}],"execution_count":39},{"cell_type":"code","source":"torch.cuda.empty_cache()","metadata":{"_uuid":"011133be-06db-4093-9092-c463080cdd2a","_cell_guid":"f03e3e51-e071-42cf-bd85-06570ed38368","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-12-16T17:07:38.511418Z","iopub.execute_input":"2024-12-16T17:07:38.512324Z","iopub.status.idle":"2024-12-16T17:07:38.517039Z","shell.execute_reply.started":"2024-12-16T17:07:38.512265Z","shell.execute_reply":"2024-12-16T17:07:38.516219Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(torch.cuda.memory_summary())","metadata":{"_uuid":"b26fc14c-f03c-4a29-ba67-b7863484b1e5","_cell_guid":"394b042d-57fd-4371-bd10-008765579754","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2024-12-16T17:11:28.010818Z","iopub.execute_input":"2024-12-16T17:11:28.011421Z","iopub.status.idle":"2024-12-16T17:11:28.016583Z","shell.execute_reply.started":"2024-12-16T17:11:28.011387Z","shell.execute_reply":"2024-12-16T17:11:28.015637Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"_uuid":"888646d8-5ba3-44e6-bd8e-778a3e8e354a","_cell_guid":"84d90ef4-9f39-476a-8075-4665e1d9a5d8","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null}]}