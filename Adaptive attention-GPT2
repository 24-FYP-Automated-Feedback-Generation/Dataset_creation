{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":10048507,"sourceType":"datasetVersion","datasetId":6190931}],"dockerImageVersionId":30804,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"a253fd50-0c38-4ed2-95be-d8de722c76c0","_cell_guid":"879296a9-98ee-4c26-be52-e01b545a2867","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-12-17T07:20:41.567060Z","iopub.execute_input":"2024-12-17T07:20:41.567862Z","iopub.status.idle":"2024-12-17T07:20:42.021211Z","shell.execute_reply.started":"2024-12-17T07:20:41.567824Z","shell.execute_reply":"2024-12-17T07:20:42.020447Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Import libraries.","metadata":{"_uuid":"1ad07d1c-cedd-4a5a-b877-8725368c6600","_cell_guid":"74f900c3-cd95-40c7-bae9-4b6e72d883a8","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"pip install transformers torch","metadata":{"_uuid":"faf8192f-ccd7-4e28-ab6c-eac95a4dbbd4","_cell_guid":"19421aeb-0fda-47bb-8161-ce259118872e","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-12-17T07:20:44.884724Z","iopub.execute_input":"2024-12-17T07:20:44.885626Z","iopub.status.idle":"2024-12-17T07:20:56.800661Z","shell.execute_reply.started":"2024-12-17T07:20:44.885591Z","shell.execute_reply":"2024-12-17T07:20:56.799568Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\nfrom torch import nn\nfrom torch.optim import Adam\nfrom torch.utils.data import DataLoader, TensorDataset\nfrom transformers import AutoModel, AutoTokenizer, GPT2Model\nfrom transformers import BertModel, BertTokenizer","metadata":{"_uuid":"18b04d16-ba61-4e7f-b8b7-01d7e2e415ce","_cell_guid":"a277c174-1d84-40ac-835d-57bb9acf5294","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-12-17T07:21:03.470072Z","iopub.execute_input":"2024-12-17T07:21:03.470821Z","iopub.status.idle":"2024-12-17T07:21:25.866347Z","shell.execute_reply.started":"2024-12-17T07:21:03.470786Z","shell.execute_reply":"2024-12-17T07:21:25.865429Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")","metadata":{"_uuid":"e83f7ea9-47b9-4a69-b419-71f3c808f848","_cell_guid":"78d1ae54-a469-4b2d-a16f-e5e355332bdd","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2024-12-17T07:20:56.810197Z","iopub.status.idle":"2024-12-17T07:20:56.810694Z","shell.execute_reply.started":"2024-12-17T07:20:56.810424Z","shell.execute_reply":"2024-12-17T07:20:56.810448Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"device","metadata":{"_uuid":"6672b61f-85ef-4a4e-b98f-792d1926c70b","_cell_guid":"39d4ccfc-f6b7-48ea-b7dd-74a879f8f5d1","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2024-12-17T07:20:56.811849Z","iopub.status.idle":"2024-12-17T07:20:56.812143Z","shell.execute_reply.started":"2024-12-17T07:20:56.812004Z","shell.execute_reply":"2024-12-17T07:20:56.812019Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Models initialization and tokenizations","metadata":{"_uuid":"79a0f677-d886-45c1-b89d-2c07a45bf4e8","_cell_guid":"e47cdfb4-289d-4e12-b5ac-294e51ee05ca","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"model_name_encoder = \"bert-base-uncased\"","metadata":{"_uuid":"30502618-88d6-445c-a040-0960f3e85c57","_cell_guid":"6876eaed-a7c6-4f47-b81e-e975f8195f9d","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-12-17T07:21:25.868040Z","iopub.execute_input":"2024-12-17T07:21:25.868709Z","iopub.status.idle":"2024-12-17T07:21:25.872977Z","shell.execute_reply.started":"2024-12-17T07:21:25.868669Z","shell.execute_reply":"2024-12-17T07:21:25.871959Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"context_encoder = AutoModel.from_pretrained(model_name_encoder)\n#this same encoder will be used as the persona encoder but with a linear projection of 16->768","metadata":{"_uuid":"d586623b-daf2-41cb-b771-d42a12d8c086","_cell_guid":"26807645-2810-40a7-ac41-2fd2f4570ca6","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2024-12-17T03:19:53.375926Z","iopub.execute_input":"2024-12-17T03:19:53.376492Z","iopub.status.idle":"2024-12-17T03:19:56.159076Z","shell.execute_reply.started":"2024-12-17T03:19:53.376452Z","shell.execute_reply":"2024-12-17T03:19:56.158171Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"context_encoder","metadata":{"_uuid":"ba950c9d-e0d7-4cd2-be21-705f747ebea8","_cell_guid":"51890bf3-d6ba-4584-be32-1b04f4dd2010","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2024-12-17T03:19:56.160351Z","iopub.execute_input":"2024-12-17T03:19:56.160674Z","iopub.status.idle":"2024-12-17T03:19:56.167507Z","shell.execute_reply.started":"2024-12-17T03:19:56.160646Z","shell.execute_reply":"2024-12-17T03:19:56.166616Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"decoder = GPT2Model.from_pretrained(\"gpt2\")","metadata":{"_uuid":"55669cac-630b-4faf-9f23-647f9c201ced","_cell_guid":"54e5e473-ff2f-48f6-8e51-1f3e545ba070","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-12-17T03:20:20.675775Z","iopub.execute_input":"2024-12-17T03:20:20.676445Z","iopub.status.idle":"2024-12-17T03:20:23.687234Z","shell.execute_reply.started":"2024-12-17T03:20:20.676412Z","shell.execute_reply":"2024-12-17T03:20:23.686276Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"decoder","metadata":{"_uuid":"ca77b275-2858-416a-80a5-fd221c880f96","_cell_guid":"6257ca8a-f10a-4145-83ab-00988be33d6a","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2024-12-17T03:20:23.688655Z","iopub.execute_input":"2024-12-17T03:20:23.688926Z","iopub.status.idle":"2024-12-17T03:20:23.695122Z","shell.execute_reply.started":"2024-12-17T03:20:23.688900Z","shell.execute_reply":"2024-12-17T03:20:23.694216Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"decoder.resize_token_embeddings(decoder.config.vocab_size)","metadata":{"_uuid":"0e73eb23-6ac0-40f2-a603-91ab421ce084","_cell_guid":"ab404c9f-d7c7-46e5-b014-fa03280a9c16","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-12-17T03:20:33.760098Z","iopub.execute_input":"2024-12-17T03:20:33.760449Z","iopub.status.idle":"2024-12-17T03:20:33.766945Z","shell.execute_reply.started":"2024-12-17T03:20:33.760416Z","shell.execute_reply":"2024-12-17T03:20:33.765990Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Tokenizer\ntokenizer_encoder = AutoTokenizer.from_pretrained(model_name_encoder)","metadata":{"_uuid":"f91b8c3f-6e41-43a8-aa84-2fe3770ef6b2","_cell_guid":"393ea443-9a48-428e-8a47-d25c1c57ac94","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-12-17T03:20:36.795476Z","iopub.execute_input":"2024-12-17T03:20:36.795805Z","iopub.status.idle":"2024-12-17T03:20:37.348150Z","shell.execute_reply.started":"2024-12-17T03:20:36.795774Z","shell.execute_reply":"2024-12-17T03:20:37.347331Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"tokenizer_encoder","metadata":{"_uuid":"89ea9f37-2e4e-40b9-981f-59201349087b","_cell_guid":"1bfb11ae-567b-4087-90cc-d77deb36cb1c","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2024-12-17T03:26:17.376069Z","iopub.execute_input":"2024-12-17T03:26:17.376428Z","iopub.status.idle":"2024-12-17T03:26:17.382803Z","shell.execute_reply.started":"2024-12-17T03:26:17.376396Z","shell.execute_reply":"2024-12-17T03:26:17.381778Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"tokenizer_decoder = AutoTokenizer.from_pretrained(\"gpt2\")","metadata":{"_uuid":"a2631078-204e-4128-b631-71d0c0b36790","_cell_guid":"f1060f7b-e782-4d4f-89d6-e93d654c37e5","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2024-12-17T03:20:40.265321Z","iopub.execute_input":"2024-12-17T03:20:40.265676Z","iopub.status.idle":"2024-12-17T03:20:41.163512Z","shell.execute_reply.started":"2024-12-17T03:20:40.265646Z","shell.execute_reply":"2024-12-17T03:20:41.162824Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Set padding token to eos_token for GPT-2\ntokenizer_decoder.pad_token = tokenizer_decoder.eos_token","metadata":{"_uuid":"cad8c52f-4f7a-4a39-987c-0eb7a4a84505","_cell_guid":"fccce296-a407-44b8-851d-413f14a39aab","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2024-12-17T03:20:43.185513Z","iopub.execute_input":"2024-12-17T03:20:43.185844Z","iopub.status.idle":"2024-12-17T03:20:43.190316Z","shell.execute_reply.started":"2024-12-17T03:20:43.185814Z","shell.execute_reply":"2024-12-17T03:20:43.189179Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Learnable projection layer for metacognitive profile\nprofile_projection = nn.Linear(16, context_encoder.config.hidden_size)","metadata":{"_uuid":"c5c87e4f-d68c-4daf-b658-a9b3852a5950","_cell_guid":"ebb66a87-db80-4743-b720-f6d58e5d7c59","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-12-17T03:20:46.235931Z","iopub.execute_input":"2024-12-17T03:20:46.236867Z","iopub.status.idle":"2024-12-17T03:20:46.244759Z","shell.execute_reply.started":"2024-12-17T03:20:46.236819Z","shell.execute_reply":"2024-12-17T03:20:46.243891Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"profile_projection","metadata":{"_uuid":"d1451a9c-d1d4-42fa-92d6-a0401868f09b","_cell_guid":"4f8b1eee-0cef-4dae-b3b8-175f7a90690c","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2024-12-17T03:20:49.345328Z","iopub.execute_input":"2024-12-17T03:20:49.345672Z","iopub.status.idle":"2024-12-17T03:20:49.350971Z","shell.execute_reply.started":"2024-12-17T03:20:49.345643Z","shell.execute_reply":"2024-12-17T03:20:49.350128Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Defining the PAA layers and Model","metadata":{"_uuid":"403d7dc7-4b5c-4822-86e7-fd478d88a4a6","_cell_guid":"4ba2867a-e595-4253-8f9e-1a3258358822","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"class PAALayer(nn.Module):\n    def __init__(self, hidden_size):\n        super(PAALayer, self).__init__()\n        self.cross_attn = nn.MultiheadAttention(hidden_size, num_heads=8)\n        self.sigmoid = nn.Sigmoid()\n        self.linear = nn.Linear(hidden_size * 2, hidden_size)\n\n    def forward(self, persona_hidden, context_hidden, decoder_hidden, tau):\n        c1, _ = self.cross_attn(decoder_hidden, persona_hidden, persona_hidden)\n        c2, _ = self.cross_attn(decoder_hidden, context_hidden, context_hidden)\n        \n        # Adaptive weight calculation\n        w1 = self.sigmoid(self.linear(torch.cat((c1, decoder_hidden), dim=-1)))\n        w2 = 1 - w1\n\n        # Mask creation\n        m1 = torch.where(w1 > tau, 0, 1)\n        m2 = torch.where(w1 < 1 - tau, 0, 1)\n\n        # Weighted summation with masks\n        paa_output = w1 * m1 * c1 + w2 * m2 * c2 + decoder_hidden\n        return paa_output","metadata":{"_uuid":"2590c9e6-7f0c-48cf-8a04-830802fba3fa","_cell_guid":"a320e327-d213-4825-813a-73fc9d40bb41","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-12-17T03:20:54.715771Z","iopub.execute_input":"2024-12-17T03:20:54.716130Z","iopub.status.idle":"2024-12-17T03:20:54.722624Z","shell.execute_reply.started":"2024-12-17T03:20:54.716099Z","shell.execute_reply":"2024-12-17T03:20:54.721703Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nclass PAA_Model(nn.Module):\n    def __init__(self, context_encoder, decoder, profile_projection, paa_layer):\n        super(PAA_Model, self).__init__()\n        self.context_encoder = context_encoder\n        self.decoder = decoder\n        self.profile_projection = profile_projection\n        self.paa_layer = paa_layer\n        self.loss_fn = nn.CrossEntropyLoss()\n\n    def forward(self, context_tokens, target_tokens, profile_vector, tau):\n        # Encode context\n        context_hidden = self.context_encoder(**context_tokens).last_hidden_state\n        print(f\"context_hidden shape: {context_hidden.shape}\")\n\n        # Project metacognitive profile\n        projected_profile = self.profile_projection(profile_vector).unsqueeze(1)\n        print(f\"projected profile shape: {projected_profile.shape}\")\n\n        # Expand persona representation\n        persona_hidden = projected_profile.expand(-1, context_hidden.size(1), -1)\n        print(f\"persona_hidden shape: {persona_hidden.shape}\")\n\n        # Resize or pad persona_hidden and context_hidden to match decoder_hidden length\n        target_length = target_tokens['input_ids'].shape[1]  # Match target sequence length (e.g., decoder_hidden length)\n        context_hidden_resized = self.resize_sequence(context_hidden, target_length)\n        persona_hidden_resized = self.resize_sequence(persona_hidden, target_length)\n\n        print(f\"Resized context_hidden shape: {context_hidden_resized.shape}\")\n        print(f\"Resized persona_hidden shape: {persona_hidden_resized.shape}\")\n\n        # Decoder's output\n        decoder_hidden = self.decoder(**target_tokens).last_hidden_state\n        print(f\"decoder_hidden shape: {decoder_hidden.shape}\")\n\n        # Apply PAA\n        paa_output = self.paa_layer(persona_hidden_resized, context_hidden_resized, decoder_hidden, tau)\n\n        # No softmax here, CrossEntropyLoss expects raw logits\n        logits = paa_output\n        target = target_tokens['input_ids'][:, 1:].contiguous().view(-1)  # Flatten target tokens\n        print(f\"logits shape: {logits.shape}\")\n        print(f\"target shape: {target.shape}\")\n\n        # Ensure logits and target have matching batch size\n        logits = logits.view(-1, logits.size(-1))  # Shape: (batch_size * seq_len, vocab_size)\n\n        assert logits.size(0) == target.size(0), f\"Batch size mismatch: logits batch size {logits.size(0)} vs target batch size {target.size(0)}\"\n\n        # Calculate loss\n        loss = self.loss_fn(logits, target)\n        return loss\n\n    def resize_sequence(self, tensor, target_length):\n        \"\"\"\n        Resize tensor sequence to the target length using padding or interpolation.\n        This method can be adjusted to use either padding or interpolation as per the requirement.\n        \"\"\"\n        current_length = tensor.size(1)\n        if current_length < target_length:\n            # Padding case\n            padding_length = target_length - current_length\n            return F.pad(tensor, (0, 0, 0, padding_length), \"constant\", 0)\n        elif current_length > target_length:\n            # Truncation case\n            return tensor[:, :target_length, :]\n        else:\n            return tensor  # No change if lengths match","metadata":{"_uuid":"a8d7c719-e84b-4a0b-9fc8-2b8a6595ff30","_cell_guid":"4d79acac-fe49-47b5-85b5-cc72e9245e08","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-12-17T03:20:59.780648Z","iopub.execute_input":"2024-12-17T03:20:59.781367Z","iopub.status.idle":"2024-12-17T03:20:59.790972Z","shell.execute_reply.started":"2024-12-17T03:20:59.781336Z","shell.execute_reply":"2024-12-17T03:20:59.789941Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Model and optimizer","metadata":{"_uuid":"6e7da9a1-cbfc-4252-b704-54fa3284718a","_cell_guid":"ec759725-103f-4caa-ba2b-053e27a761a1","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"paa_layer = PAALayer(context_encoder.config.hidden_size)","metadata":{"_uuid":"9ce494c2-a4b5-4253-824f-29793100e9e5","_cell_guid":"dc990149-545b-4e00-ba99-412c1b1f959a","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-12-17T03:21:03.265181Z","iopub.execute_input":"2024-12-17T03:21:03.265531Z","iopub.status.idle":"2024-12-17T03:21:03.295814Z","shell.execute_reply.started":"2024-12-17T03:21:03.265499Z","shell.execute_reply":"2024-12-17T03:21:03.295214Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"paa_layer","metadata":{"_uuid":"329df787-7310-4ca3-93f1-cd07d724cde5","_cell_guid":"4de6dcac-7285-430b-aee9-c58f8428b141","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2024-12-17T03:21:05.705134Z","iopub.execute_input":"2024-12-17T03:21:05.705435Z","iopub.status.idle":"2024-12-17T03:21:05.710899Z","shell.execute_reply.started":"2024-12-17T03:21:05.705408Z","shell.execute_reply":"2024-12-17T03:21:05.710062Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model = PAA_Model(context_encoder, decoder, profile_projection, paa_layer).to(device)","metadata":{"_uuid":"aaf3ec0f-092c-4443-b0ff-37b03e54472d","_cell_guid":"b7b44998-9108-4851-90de-97b48752cf17","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-12-17T03:21:26.015247Z","iopub.execute_input":"2024-12-17T03:21:26.015551Z","iopub.status.idle":"2024-12-17T03:21:26.502035Z","shell.execute_reply.started":"2024-12-17T03:21:26.015525Z","shell.execute_reply":"2024-12-17T03:21:26.501334Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model","metadata":{"_uuid":"d3b6f5ec-e141-49e9-8f63-3eab69163e68","_cell_guid":"e419196b-e304-4c73-a490-d80444e9f7e5","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2024-12-17T03:21:28.750644Z","iopub.execute_input":"2024-12-17T03:21:28.750929Z","iopub.status.idle":"2024-12-17T03:21:28.757993Z","shell.execute_reply.started":"2024-12-17T03:21:28.750904Z","shell.execute_reply":"2024-12-17T03:21:28.757152Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"optimizer = Adam(model.parameters(), lr=5e-5)","metadata":{"_uuid":"6728cace-2cd5-484c-9286-5fd901ae92b2","_cell_guid":"8b7ca88a-639d-4beb-ac82-6d5ab5a784b1","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-12-17T03:23:16.496291Z","iopub.execute_input":"2024-12-17T03:23:16.497046Z","iopub.status.idle":"2024-12-17T03:23:16.502307Z","shell.execute_reply.started":"2024-12-17T03:23:16.497014Z","shell.execute_reply":"2024-12-17T03:23:16.501444Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Dataset preparation","metadata":{"_uuid":"cf3edd41-4ce2-46b7-b8ba-665d2ada3230","_cell_guid":"ad28038e-14a2-4375-b356-33bce9e119c8","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"file_path = \"/kaggle/input/modified-dataset/modified_dataset.csv\"\ndf = pd.read_csv(file_path)","metadata":{"_uuid":"01326d00-ef5a-402b-b16d-c0ff3e7960c7","_cell_guid":"cc4cef47-43c2-4ddd-bd8e-66597196f7a8","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-12-17T07:21:25.873881Z","iopub.execute_input":"2024-12-17T07:21:25.874133Z","iopub.status.idle":"2024-12-17T07:21:25.939770Z","shell.execute_reply.started":"2024-12-17T07:21:25.874108Z","shell.execute_reply":"2024-12-17T07:21:25.939117Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df.head(5)","metadata":{"_uuid":"35193af2-5f44-4b4e-b78e-15350adc2303","_cell_guid":"4755caab-f924-4d4a-bb57-a2f840b77399","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-12-17T07:21:25.941473Z","iopub.execute_input":"2024-12-17T07:21:25.941811Z","iopub.status.idle":"2024-12-17T07:21:25.971584Z","shell.execute_reply.started":"2024-12-17T07:21:25.941771Z","shell.execute_reply":"2024-12-17T07:21:25.970537Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"len(df)","metadata":{"_uuid":"16057344-5f6e-4f61-9c43-266129b302a2","_cell_guid":"1b828457-174d-4f32-83d9-df511b1211a3","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-12-17T03:25:07.656295Z","iopub.execute_input":"2024-12-17T03:25:07.656641Z","iopub.status.idle":"2024-12-17T03:25:07.662314Z","shell.execute_reply.started":"2024-12-17T03:25:07.656610Z","shell.execute_reply":"2024-12-17T03:25:07.661287Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"len(list(df['description']))","metadata":{"_uuid":"d646c61f-941a-4e1f-a6de-5f345f0af03b","_cell_guid":"152d555b-f34f-4b99-8b07-a45690325097","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2024-12-17T03:25:44.656848Z","iopub.execute_input":"2024-12-17T03:25:44.657666Z","iopub.status.idle":"2024-12-17T03:25:44.662746Z","shell.execute_reply.started":"2024-12-17T03:25:44.657628Z","shell.execute_reply":"2024-12-17T03:25:44.661923Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import ast\ndef tokenize_data(df, tokenizer_encoder,tokenizer_decoder):\n    context_tokens = tokenizer_encoder(list(df['description']), padding=True, truncation=True, return_tensors=\"pt\")\n    target_tokens = tokenizer_decoder(list(df['metacognitive_feedback']), padding=True, truncation=True, return_tensors=\"pt\")\n    profile_vectors = torch.tensor([ast.literal_eval(profile) for profile in df['metacognitive_profile']], dtype=torch.float)\n    return context_tokens, target_tokens, profile_vectors","metadata":{"_uuid":"fed6a7a7-d6a0-4a9a-a803-530938343446","_cell_guid":"7fdbe31b-907e-4ae7-abdc-d8b0a1a1dcc0","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-12-17T03:23:31.896044Z","iopub.execute_input":"2024-12-17T03:23:31.896666Z","iopub.status.idle":"2024-12-17T03:23:31.901631Z","shell.execute_reply.started":"2024-12-17T03:23:31.896632Z","shell.execute_reply":"2024-12-17T03:23:31.900687Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"context_tokens, target_tokens, profile_vectors = tokenize_data(df, tokenizer_encoder,tokenizer_decoder)","metadata":{"_uuid":"a44c727f-722b-46dd-9874-2bd7b277ee27","_cell_guid":"502a6455-0e9a-4d8b-89eb-bb75a612ce88","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2024-12-17T03:23:35.760810Z","iopub.execute_input":"2024-12-17T03:23:35.761670Z","iopub.status.idle":"2024-12-17T03:23:36.180240Z","shell.execute_reply.started":"2024-12-17T03:23:35.761631Z","shell.execute_reply":"2024-12-17T03:23:36.179516Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"len(target_tokens)","metadata":{"_uuid":"0df4ff65-67d0-4367-a393-17b564249cf2","_cell_guid":"99140815-f0ba-4cf8-a945-18d38bbea3b6","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2024-12-17T03:24:22.895921Z","iopub.execute_input":"2024-12-17T03:24:22.896682Z","iopub.status.idle":"2024-12-17T03:24:22.902789Z","shell.execute_reply.started":"2024-12-17T03:24:22.896624Z","shell.execute_reply":"2024-12-17T03:24:22.901713Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"profile_vectors","metadata":{"_uuid":"d5511411-5da8-4e31-b9d0-be4b17b723b7","_cell_guid":"4fc1564d-1e14-4e6a-b2c3-d53d278b40c3","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2024-12-17T03:24:37.355597Z","iopub.execute_input":"2024-12-17T03:24:37.355935Z","iopub.status.idle":"2024-12-17T03:24:37.386198Z","shell.execute_reply.started":"2024-12-17T03:24:37.355905Z","shell.execute_reply":"2024-12-17T03:24:37.385211Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"context_tokens = {key: value.to(device) for key, value in context_tokens.items()}\ntarget_tokens = {key: value.to(device) for key, value in target_tokens.items()}\nprofile_vectors = profile_vectors.to(device)","metadata":{"_uuid":"02b04bb3-4dac-4d9d-bedf-93c7e33a65be","_cell_guid":"48d3d450-8fdc-48de-8d99-05587d0d3eac","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2024-12-17T03:26:46.460774Z","iopub.execute_input":"2024-12-17T03:26:46.461436Z","iopub.status.idle":"2024-12-17T03:26:46.482051Z","shell.execute_reply.started":"2024-12-17T03:26:46.461397Z","shell.execute_reply":"2024-12-17T03:26:46.481185Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Create DataLoader\ntrain_data = TensorDataset(context_tokens['input_ids'], target_tokens['input_ids'], profile_vectors)\ntrain_loader = DataLoader(train_data, batch_size=8, shuffle=True)","metadata":{"_uuid":"074a07c6-02f9-44e0-8c64-967ca78f8250","_cell_guid":"d655b657-635d-42b9-9c99-8ef9c7c7af02","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-12-17T03:26:54.280836Z","iopub.execute_input":"2024-12-17T03:26:54.281154Z","iopub.status.idle":"2024-12-17T03:26:54.285616Z","shell.execute_reply.started":"2024-12-17T03:26:54.281127Z","shell.execute_reply":"2024-12-17T03:26:54.284698Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Training loop","metadata":{"_uuid":"94e3aace-7107-4a82-a83f-e6403a3ad4c7","_cell_guid":"a1b089b5-2fdf-4b22-ac39-fe4f7d0d368a","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"model.train()\nnum_epochs = 5\ntau = 0.5\n\nfor epoch in range(num_epochs):\n    total_loss = 0\n    for context_ids, target_ids, profile_vector in train_loader:\n        # Move tensors to the GPU (if available)\n        context_ids = context_ids.to(device)\n        target_ids = target_ids.to(device)\n        profile_vector = profile_vector.to(device)\n\n        optimizer.zero_grad()\n\n        # Prepare input tensors\n        context_tokens = {'input_ids': context_ids, 'attention_mask': context_ids != tokenizer_encoder.pad_token_id}\n        target_tokens = {'input_ids': target_ids, 'attention_mask': target_ids != tokenizer_decoder.pad_token_id}\n\n        # Forward pass through the model\n        loss = model(context_tokens, target_tokens, profile_vector, tau)\n\n        # Backpropagate and update the model\n        loss.backward()\n        optimizer.step()\n        total_loss += loss.item()\n\n    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {total_loss/len(train_loader)}\")","metadata":{"_uuid":"bf476f50-8f76-4429-afd0-2f47630fa9dc","_cell_guid":"2347f634-be12-45b1-8d79-d1f0bb114c8a","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-12-17T03:26:58.135783Z","iopub.execute_input":"2024-12-17T03:26:58.136128Z","iopub.status.idle":"2024-12-17T03:27:00.030683Z","shell.execute_reply.started":"2024-12-17T03:26:58.136098Z","shell.execute_reply":"2024-12-17T03:27:00.029527Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"torch.cuda.empty_cache()","metadata":{"_uuid":"7a922bc4-5777-4a1c-9e5a-bd820b02e268","_cell_guid":"e6548ec5-b73a-48ec-832e-c1865f3b9fb3","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-12-16T17:07:38.511418Z","iopub.execute_input":"2024-12-16T17:07:38.512324Z","iopub.status.idle":"2024-12-16T17:07:38.517039Z","shell.execute_reply.started":"2024-12-16T17:07:38.512265Z","shell.execute_reply":"2024-12-16T17:07:38.516219Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(torch.cuda.memory_summary())","metadata":{"_uuid":"ec7b2129-3b55-4f70-985c-b764d7c43a0e","_cell_guid":"c57c0ba7-bba8-4ebc-9c2e-ef5ad6ca52c0","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2024-12-16T17:11:28.010818Z","iopub.execute_input":"2024-12-16T17:11:28.011421Z","iopub.status.idle":"2024-12-16T17:11:28.016583Z","shell.execute_reply.started":"2024-12-16T17:11:28.011387Z","shell.execute_reply":"2024-12-16T17:11:28.015637Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Context Encoder","metadata":{"_uuid":"a54f4e1e-7bac-4e3e-9456-28a9f70ef0c0","_cell_guid":"acd7f754-97d2-472f-8cd8-8a17691e400d","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"encoder = BertModel.from_pretrained(model_name_encoder)","metadata":{"_uuid":"a39c6371-5059-45b5-9ab1-f028d7456565","_cell_guid":"06d0cb18-5076-4128-aa7d-4ebeb504be81","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-12-17T07:22:00.874601Z","iopub.execute_input":"2024-12-17T07:22:00.875420Z","iopub.status.idle":"2024-12-17T07:22:01.025145Z","shell.execute_reply.started":"2024-12-17T07:22:00.875350Z","shell.execute_reply":"2024-12-17T07:22:01.024523Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"tokenizer_encoder = BertTokenizer.from_pretrained(model_name_encoder)","metadata":{"_uuid":"a89927c0-4e9a-47aa-a9dd-fcc6bb02f3b1","_cell_guid":"10fd9213-45db-4d6a-a89c-6231690ce158","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2024-12-17T07:22:04.950957Z","iopub.execute_input":"2024-12-17T07:22:04.951279Z","iopub.status.idle":"2024-12-17T07:22:05.047041Z","shell.execute_reply.started":"2024-12-17T07:22:04.951249Z","shell.execute_reply":"2024-12-17T07:22:05.046308Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Function to encode context\ndef encode_context(description, student_code, feedback, max_len=512):\n    context = f\"Description: {description} Student Code: {student_code} Feedback: {feedback}\"\n    inputs = tokenizer_encoder(\n        context, \n        padding='max_length', \n        truncation=True, \n        max_length=max_len, \n        return_tensors='pt'\n    )\n    return inputs","metadata":{"_uuid":"41b25e5d-60fe-4bb1-b89c-bbeed9ff13ee","_cell_guid":"92a5215c-abaa-445b-a0ac-278dfd56b1a1","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2024-12-17T07:22:36.595052Z","iopub.execute_input":"2024-12-17T07:22:36.596018Z","iopub.status.idle":"2024-12-17T07:22:36.601250Z","shell.execute_reply.started":"2024-12-17T07:22:36.595965Z","shell.execute_reply":"2024-12-17T07:22:36.600427Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"encoded_context = []","metadata":{"_uuid":"ce0f4149-0c29-4f74-ba75-aa50b1564395","_cell_guid":"e53555c7-178b-47af-87b8-53707eb22005","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2024-12-17T07:22:11.179797Z","iopub.execute_input":"2024-12-17T07:22:11.180927Z","iopub.status.idle":"2024-12-17T07:22:11.184979Z","shell.execute_reply.started":"2024-12-17T07:22:11.180881Z","shell.execute_reply":"2024-12-17T07:22:11.184152Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"for idx, row in df.iterrows():\n    description = row['description']\n    student_code = row['student_code']\n    feedback = row['feedback']\n    \n    # Encode context (IU)\n    context_inputs = encode_context(student_code, feedback, description)\n\n    # Get BERT hidden states\n    with torch.no_grad():\n        hU = encoder(**context_inputs).last_hidden_state  # Shape: (1, max_len, 768)\n\n    encoded_context.append(hU.squeeze(0))\n    print(len(encoded_context))","metadata":{"_uuid":"baa2843a-52f7-43fd-8aac-d54f8a28d8c5","_cell_guid":"05dee144-6050-48e0-ae36-94902555b9ca","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2024-12-17T07:23:49.835039Z","iopub.execute_input":"2024-12-17T07:23:49.835345Z","iopub.status.idle":"2024-12-17T07:26:42.829537Z","shell.execute_reply.started":"2024-12-17T07:23:49.835317Z","shell.execute_reply":"2024-12-17T07:26:42.828658Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(f\"Encoded Context Shape: {encoded_context[0].shape}\")","metadata":{"_uuid":"adb19207-b959-45dc-8128-13c6bd21c436","_cell_guid":"ec4ca9f1-48a4-4d45-9403-eeadd1dbcd47","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2024-12-17T07:29:02.920115Z","iopub.execute_input":"2024-12-17T07:29:02.920960Z","iopub.status.idle":"2024-12-17T07:29:02.925332Z","shell.execute_reply.started":"2024-12-17T07:29:02.920926Z","shell.execute_reply":"2024-12-17T07:29:02.924286Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"encoded_context[0]","metadata":{"_uuid":"d7098c76-9110-4f46-8f58-0aa1c5ee0fe9","_cell_guid":"9a0f8b1a-f1c1-40e5-a6b9-969b0763a0c9","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2024-12-17T07:29:29.144538Z","iopub.execute_input":"2024-12-17T07:29:29.145175Z","iopub.status.idle":"2024-12-17T07:29:29.212816Z","shell.execute_reply.started":"2024-12-17T07:29:29.145144Z","shell.execute_reply":"2024-12-17T07:29:29.212099Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class ContextEncoder(nn.Module):\n    def __init__(self, bert_model_name='bert-base-uncased', output_dim=768):\n        super(ContextEncoder, self).__init__()\n        \n        # BERT model for encoding the context (student_code, feedback, description)\n        self.tokenizer = BertTokenizer.from_pretrained(bert_model_name)\n        self.bert_encoder = BertModel.from_pretrained(bert_model_name)\n        \n        # Optional: Linear layer to project BERT output to the desired dimension\n        self.fc = nn.Linear(self.bert_encoder.config.hidden_size, output_dim)\n\n    def forward(self, description, student_code, feedback):\n        # Combine the context information (description, student_code, feedback)\n        context = f\"Description: {description} Student Code: {student_code} Feedback: {feedback}\"\n        \n        # Tokenize the input context and prepare it for BERT\n        encoded_inputs = self.tokenizer(\n            context, \n            return_tensors='pt', \n            padding='max_length', \n            truncation=True, \n            max_length=512\n        )\n        \n        # Encode the context using BERT\n        with torch.no_grad():\n            context_hidden_states = self.bert_encoder(**encoded_inputs).last_hidden_state  # (batch_size, seq_len, hidden_dim)\n        \n        # Take the mean of the hidden states across the sequence length to get a fixed-size representation\n        context_rep = context_hidden_states.mean(dim=1)  # (batch_size, hidden_dim)\n        \n        context_rep = self.fc(context_rep)  # (batch_size, output_dim)\n        \n        return context_rep","metadata":{"_uuid":"f74b60da-0791-433b-8273-8bbc2e262947","_cell_guid":"a0554a5d-0cc3-42b0-afe9-b3605296e57b","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2024-12-17T07:49:00.200317Z","iopub.execute_input":"2024-12-17T07:49:00.201257Z","iopub.status.idle":"2024-12-17T07:49:00.207677Z","shell.execute_reply.started":"2024-12-17T07:49:00.201217Z","shell.execute_reply":"2024-12-17T07:49:00.206841Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"context_encoder = ContextEncoder()","metadata":{"_uuid":"4c808304-de9e-434f-8b57-1d795efcf084","_cell_guid":"7ac1b345-eb9a-43db-86b2-90aa33d65e6e","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2024-12-17T07:49:03.505017Z","iopub.execute_input":"2024-12-17T07:49:03.505946Z","iopub.status.idle":"2024-12-17T07:49:04.106685Z","shell.execute_reply.started":"2024-12-17T07:49:03.505911Z","shell.execute_reply":"2024-12-17T07:49:04.106000Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"context=[]","metadata":{"_uuid":"dafbf2d2-65d0-4960-8db4-8549dce8dabb","_cell_guid":"95056cd7-603c-4170-84c5-9e517139add4","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2024-12-17T07:49:07.030213Z","iopub.execute_input":"2024-12-17T07:49:07.030889Z","iopub.status.idle":"2024-12-17T07:49:07.034392Z","shell.execute_reply.started":"2024-12-17T07:49:07.030855Z","shell.execute_reply":"2024-12-17T07:49:07.033535Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"for idx, row in df.iterrows():\n    description = row['description']\n    student_code = row['student_code']\n    feedback = row['feedback']\n    \n    # Get the context representation by passing the description, student_code, and feedback\n    context_rep = context_encoder(description, student_code, feedback)\n    \n    # Append the result to the encoded context list\n    context.append(context_rep)\n    print(len(context))","metadata":{"_uuid":"e56e7167-679e-4349-9964-71fe45a20438","_cell_guid":"3f9e3a8a-5ba8-4e28-98f4-7478876313b9","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2024-12-17T07:49:52.064721Z","iopub.execute_input":"2024-12-17T07:49:52.065056Z","iopub.status.idle":"2024-12-17T07:52:50.698070Z","shell.execute_reply.started":"2024-12-17T07:49:52.065024Z","shell.execute_reply":"2024-12-17T07:52:50.697133Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(context[0].shape)","metadata":{"_uuid":"bf333806-c81f-45ee-b5ba-7d19dafdeb5e","_cell_guid":"f17a0c4a-03e8-4a08-afab-421d2aa48612","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2024-12-17T07:53:45.670548Z","iopub.execute_input":"2024-12-17T07:53:45.671362Z","iopub.status.idle":"2024-12-17T07:53:45.676745Z","shell.execute_reply.started":"2024-12-17T07:53:45.671308Z","shell.execute_reply":"2024-12-17T07:53:45.675709Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"context[0]","metadata":{"_uuid":"f38b8ebf-bf7d-4f7b-a626-64088718109c","_cell_guid":"9cbab324-f885-4773-b26b-db511b8df145","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2024-12-17T08:04:07.314666Z","iopub.execute_input":"2024-12-17T08:04:07.315591Z","iopub.status.idle":"2024-12-17T08:04:07.326179Z","shell.execute_reply.started":"2024-12-17T08:04:07.315554Z","shell.execute_reply":"2024-12-17T08:04:07.325321Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Persona Encoder","metadata":{"_uuid":"c361dd0d-650e-476f-ba5e-7e2d0b828f5a","_cell_guid":"dc447f6d-ee00-42b3-b5cf-ad411c982f33","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"class PersonaEncoder(nn.Module):\n    def __init__(self, metacognitive_dim=16, output_dim=768):\n        super(PersonaEncoder, self).__init__()\n        \n        # Linear layer to map the metacognitive vector to the output dimension\n        self.metacognitive_fc = nn.Linear(metacognitive_dim, output_dim)  # from 16 to 768\n        \n        # Final projection layer to further process the output\n        self.final_fc = nn.Linear(output_dim, output_dim)\n\n    def forward(self, metacognitive_vector):\n        # Process the metacognitive vector through the linear layer\n        metacognitive_rep = self.metacognitive_fc(metacognitive_vector)  # (batch_size, output_dim)\n        \n        # Optionally, apply another linear layer or activation if necessary\n        final_rep = self.final_fc(metacognitive_rep)  # (batch_size, output_dim)\n        \n        return final_rep","metadata":{"_uuid":"223b0a76-4222-40ab-bc06-b0fb4508f33e","_cell_guid":"be7a4518-16cf-4c13-bc91-36dbdca41905","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2024-12-17T07:54:45.579992Z","iopub.execute_input":"2024-12-17T07:54:45.580579Z","iopub.status.idle":"2024-12-17T07:54:45.585546Z","shell.execute_reply.started":"2024-12-17T07:54:45.580544Z","shell.execute_reply":"2024-12-17T07:54:45.584686Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"persona_encoder = PersonaEncoder()","metadata":{"_uuid":"2b06f448-b5eb-478b-ad21-7d131941f112","_cell_guid":"3a73de3f-bb58-4b0f-b60a-139c010d8769","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2024-12-17T07:54:52.715037Z","iopub.execute_input":"2024-12-17T07:54:52.715383Z","iopub.status.idle":"2024-12-17T07:54:52.727510Z","shell.execute_reply.started":"2024-12-17T07:54:52.715338Z","shell.execute_reply":"2024-12-17T07:54:52.726724Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"encoded_persona=[]","metadata":{"_uuid":"b6141891-7c7b-4341-b2b0-96aa8cccde8f","_cell_guid":"a94c268f-1ae0-4f1e-bbc2-8b6293ba70e5","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2024-12-17T07:56:24.749784Z","iopub.execute_input":"2024-12-17T07:56:24.750419Z","iopub.status.idle":"2024-12-17T07:56:24.753758Z","shell.execute_reply.started":"2024-12-17T07:56:24.750386Z","shell.execute_reply":"2024-12-17T07:56:24.752959Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import ast\nfor idx, row in df.iterrows():\n        # Convert the string representation of the list to an actual list of integers\n        #metacognitive_vector = ast.literal_eval(row['metacognitive_profile'])\n        metacognitive_tensor = torch.tensor([ast.literal_eval(profile) for profile in df['metacognitive_profile']], dtype=torch.float)\n        \n        # Convert to a PyTorch tensor of shape (1, 16)\n        #metacognitive_tensor = torch.tensor(metacognitive_vector, dtype=torch.float32).unsqueeze(0)\n        \n        # Encode using the PersonaEncoder\n        persona_rep = persona_encoder(metacognitive_tensor)\n        \n        # Append result to the list\n        encoded_persona.append(persona_rep)\n        print(f\"Encoded persona {idx+1}/{len(df)}\")","metadata":{"_uuid":"95cb66ff-8644-4921-b0ef-bbcf389bf474","_cell_guid":"e1942726-3cc6-4c84-9de7-c48e85378431","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2024-12-17T08:02:57.989349Z","iopub.execute_input":"2024-12-17T08:02:57.989739Z","iopub.status.idle":"2024-12-17T08:03:03.138744Z","shell.execute_reply.started":"2024-12-17T08:02:57.989710Z","shell.execute_reply":"2024-12-17T08:03:03.137709Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"encoded_persona[0].shape","metadata":{"_uuid":"6557deba-b0b1-4234-95fe-5d72fcb9ecb7","_cell_guid":"ebc0d3ff-25d6-4bd6-8ccb-e025ed999891","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2024-12-17T08:03:34.274281Z","iopub.execute_input":"2024-12-17T08:03:34.274968Z","iopub.status.idle":"2024-12-17T08:03:34.280398Z","shell.execute_reply.started":"2024-12-17T08:03:34.274934Z","shell.execute_reply":"2024-12-17T08:03:34.279572Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"encoded_persona[365]","metadata":{"_uuid":"f2436afd-1a2e-4d55-ad22-120412ab404b","_cell_guid":"294930e9-61c7-4e4b-aca3-1670267381fa","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2024-12-17T08:04:50.395796Z","iopub.execute_input":"2024-12-17T08:04:50.396482Z","iopub.status.idle":"2024-12-17T08:04:50.403762Z","shell.execute_reply.started":"2024-12-17T08:04:50.396447Z","shell.execute_reply":"2024-12-17T08:04:50.402909Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"len(encoded_persona)","metadata":{"_uuid":"54304fe4-1ac4-4b49-a40e-74f31032d9bb","_cell_guid":"52ebe085-8006-41e2-ad60-f2a09a2df698","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2024-12-17T08:04:38.230904Z","iopub.execute_input":"2024-12-17T08:04:38.231243Z","iopub.status.idle":"2024-12-17T08:04:38.236596Z","shell.execute_reply.started":"2024-12-17T08:04:38.231210Z","shell.execute_reply":"2024-12-17T08:04:38.235614Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Stack context and persona encodings into tensors\nencoded_context_tensor = torch.cat(encoded_context, dim=0)  # Shape: [N, 768]\nencoded_persona_tensor = torch.stack(encoded_persona, dim=0)  # Shape: [M, 768]","metadata":{"_uuid":"246e78f1-1385-4913-9bef-cdba468b436a","_cell_guid":"02207754-99c9-42c0-95c3-a60afcbe9d9f","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2024-12-17T08:09:25.865167Z","iopub.execute_input":"2024-12-17T08:09:25.865852Z","iopub.status.idle":"2024-12-17T08:09:26.350915Z","shell.execute_reply.started":"2024-12-17T08:09:25.865817Z","shell.execute_reply":"2024-12-17T08:09:26.349904Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(\"the encoded context tensor dimensions:\",encoded_context_tensor.shape)","metadata":{"_uuid":"a629c5c9-ceed-466e-bdea-9c9afe4a2388","_cell_guid":"cfbf5ca5-b31b-4f46-8e61-15876d0b4e01","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2024-12-17T08:12:53.626625Z","iopub.execute_input":"2024-12-17T08:12:53.627077Z","iopub.status.idle":"2024-12-17T08:12:53.632972Z","shell.execute_reply.started":"2024-12-17T08:12:53.627032Z","shell.execute_reply":"2024-12-17T08:12:53.631930Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(\"the encoded persona tensor dimensions:\",encoded_persona_tensor.shape)","metadata":{"_uuid":"80d6c22d-7b2e-4158-b4db-31f4ad1d707f","_cell_guid":"72570788-ab31-4285-aafa-77079b364eae","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2024-12-17T08:12:55.935278Z","iopub.execute_input":"2024-12-17T08:12:55.935887Z","iopub.status.idle":"2024-12-17T08:12:55.940470Z","shell.execute_reply.started":"2024-12-17T08:12:55.935855Z","shell.execute_reply":"2024-12-17T08:12:55.939656Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"_uuid":"71d4f913-ea96-4832-a7f9-100ca1640c91","_cell_guid":"7331676f-d099-43ce-aed8-1eab6262ecd2","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# PAA Layer","metadata":{"_uuid":"04a41811-8b4d-43e4-9be4-7594ab95dc60","_cell_guid":"f3198c17-0559-4904-9269-17c05a196160","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"","metadata":{"_uuid":"38e22573-3027-4a51-98b8-e533d286fc0d","_cell_guid":"98759362-3917-4709-afe7-cebc9c9a4513","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null}]}